{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "name": "Neural Network Assignment 1.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HimanshuSahoo/Himanshu_Python/blob/main/Neural_Network_Assignment_1_Forestfires.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6c7868d8"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "id": "6c7868d8",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5a181fb2"
      },
      "source": [
        "df=pd.read_csv(\"forestfires.csv\")"
      ],
      "id": "5a181fb2",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "id": "b8eef1e8",
        "outputId": "19038b61-b949-4ca9-ee6e-302198fce17a"
      },
      "source": [
        "df"
      ],
      "id": "b8eef1e8",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>month</th>\n",
              "      <th>day</th>\n",
              "      <th>FFMC</th>\n",
              "      <th>DMC</th>\n",
              "      <th>DC</th>\n",
              "      <th>ISI</th>\n",
              "      <th>temp</th>\n",
              "      <th>RH</th>\n",
              "      <th>wind</th>\n",
              "      <th>rain</th>\n",
              "      <th>area</th>\n",
              "      <th>dayfri</th>\n",
              "      <th>daymon</th>\n",
              "      <th>daysat</th>\n",
              "      <th>daysun</th>\n",
              "      <th>daythu</th>\n",
              "      <th>daytue</th>\n",
              "      <th>daywed</th>\n",
              "      <th>monthapr</th>\n",
              "      <th>monthaug</th>\n",
              "      <th>monthdec</th>\n",
              "      <th>monthfeb</th>\n",
              "      <th>monthjan</th>\n",
              "      <th>monthjul</th>\n",
              "      <th>monthjun</th>\n",
              "      <th>monthmar</th>\n",
              "      <th>monthmay</th>\n",
              "      <th>monthnov</th>\n",
              "      <th>monthoct</th>\n",
              "      <th>monthsep</th>\n",
              "      <th>size_category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>mar</td>\n",
              "      <td>fri</td>\n",
              "      <td>86.2</td>\n",
              "      <td>26.2</td>\n",
              "      <td>94.3</td>\n",
              "      <td>5.1</td>\n",
              "      <td>8.2</td>\n",
              "      <td>51</td>\n",
              "      <td>6.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>small</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>oct</td>\n",
              "      <td>tue</td>\n",
              "      <td>90.6</td>\n",
              "      <td>35.4</td>\n",
              "      <td>669.1</td>\n",
              "      <td>6.7</td>\n",
              "      <td>18.0</td>\n",
              "      <td>33</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>small</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>oct</td>\n",
              "      <td>sat</td>\n",
              "      <td>90.6</td>\n",
              "      <td>43.7</td>\n",
              "      <td>686.9</td>\n",
              "      <td>6.7</td>\n",
              "      <td>14.6</td>\n",
              "      <td>33</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>small</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>mar</td>\n",
              "      <td>fri</td>\n",
              "      <td>91.7</td>\n",
              "      <td>33.3</td>\n",
              "      <td>77.5</td>\n",
              "      <td>9.0</td>\n",
              "      <td>8.3</td>\n",
              "      <td>97</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>small</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>mar</td>\n",
              "      <td>sun</td>\n",
              "      <td>89.3</td>\n",
              "      <td>51.3</td>\n",
              "      <td>102.2</td>\n",
              "      <td>9.6</td>\n",
              "      <td>11.4</td>\n",
              "      <td>99</td>\n",
              "      <td>1.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>small</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>512</th>\n",
              "      <td>aug</td>\n",
              "      <td>sun</td>\n",
              "      <td>81.6</td>\n",
              "      <td>56.7</td>\n",
              "      <td>665.6</td>\n",
              "      <td>1.9</td>\n",
              "      <td>27.8</td>\n",
              "      <td>32</td>\n",
              "      <td>2.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.44</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>large</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>513</th>\n",
              "      <td>aug</td>\n",
              "      <td>sun</td>\n",
              "      <td>81.6</td>\n",
              "      <td>56.7</td>\n",
              "      <td>665.6</td>\n",
              "      <td>1.9</td>\n",
              "      <td>21.9</td>\n",
              "      <td>71</td>\n",
              "      <td>5.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>54.29</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>large</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>514</th>\n",
              "      <td>aug</td>\n",
              "      <td>sun</td>\n",
              "      <td>81.6</td>\n",
              "      <td>56.7</td>\n",
              "      <td>665.6</td>\n",
              "      <td>1.9</td>\n",
              "      <td>21.2</td>\n",
              "      <td>70</td>\n",
              "      <td>6.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.16</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>large</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>515</th>\n",
              "      <td>aug</td>\n",
              "      <td>sat</td>\n",
              "      <td>94.4</td>\n",
              "      <td>146.0</td>\n",
              "      <td>614.7</td>\n",
              "      <td>11.3</td>\n",
              "      <td>25.6</td>\n",
              "      <td>42</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>small</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>516</th>\n",
              "      <td>nov</td>\n",
              "      <td>tue</td>\n",
              "      <td>79.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>106.7</td>\n",
              "      <td>1.1</td>\n",
              "      <td>11.8</td>\n",
              "      <td>31</td>\n",
              "      <td>4.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>small</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>517 rows × 31 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    month  day  FFMC    DMC  ...  monthnov  monthoct  monthsep  size_category\n",
              "0     mar  fri  86.2   26.2  ...         0         0         0          small\n",
              "1     oct  tue  90.6   35.4  ...         0         1         0          small\n",
              "2     oct  sat  90.6   43.7  ...         0         1         0          small\n",
              "3     mar  fri  91.7   33.3  ...         0         0         0          small\n",
              "4     mar  sun  89.3   51.3  ...         0         0         0          small\n",
              "..    ...  ...   ...    ...  ...       ...       ...       ...            ...\n",
              "512   aug  sun  81.6   56.7  ...         0         0         0          large\n",
              "513   aug  sun  81.6   56.7  ...         0         0         0          large\n",
              "514   aug  sun  81.6   56.7  ...         0         0         0          large\n",
              "515   aug  sat  94.4  146.0  ...         0         0         0          small\n",
              "516   nov  tue  79.5    3.0  ...         1         0         0          small\n",
              "\n",
              "[517 rows x 31 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8ccff2f",
        "outputId": "72c6f532-d0e6-462e-bc51-6c4c182f23e0"
      },
      "source": [
        "#changing size_category to numerical data\n",
        "df['size_category'].unique()"
      ],
      "id": "b8ccff2f",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['small', 'large'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71bd9dbc"
      },
      "source": [
        "df.size_category.replace(('small','large'),(1,2),inplace=True)"
      ],
      "id": "71bd9dbc",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "a4c4ab7f",
        "outputId": "59e1392a-414d-4f01-ef12-bcc5c8dfc5a1"
      },
      "source": [
        "df.head()"
      ],
      "id": "a4c4ab7f",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>month</th>\n",
              "      <th>day</th>\n",
              "      <th>FFMC</th>\n",
              "      <th>DMC</th>\n",
              "      <th>DC</th>\n",
              "      <th>ISI</th>\n",
              "      <th>temp</th>\n",
              "      <th>RH</th>\n",
              "      <th>wind</th>\n",
              "      <th>rain</th>\n",
              "      <th>area</th>\n",
              "      <th>dayfri</th>\n",
              "      <th>daymon</th>\n",
              "      <th>daysat</th>\n",
              "      <th>daysun</th>\n",
              "      <th>daythu</th>\n",
              "      <th>daytue</th>\n",
              "      <th>daywed</th>\n",
              "      <th>monthapr</th>\n",
              "      <th>monthaug</th>\n",
              "      <th>monthdec</th>\n",
              "      <th>monthfeb</th>\n",
              "      <th>monthjan</th>\n",
              "      <th>monthjul</th>\n",
              "      <th>monthjun</th>\n",
              "      <th>monthmar</th>\n",
              "      <th>monthmay</th>\n",
              "      <th>monthnov</th>\n",
              "      <th>monthoct</th>\n",
              "      <th>monthsep</th>\n",
              "      <th>size_category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>mar</td>\n",
              "      <td>fri</td>\n",
              "      <td>86.2</td>\n",
              "      <td>26.2</td>\n",
              "      <td>94.3</td>\n",
              "      <td>5.1</td>\n",
              "      <td>8.2</td>\n",
              "      <td>51</td>\n",
              "      <td>6.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>oct</td>\n",
              "      <td>tue</td>\n",
              "      <td>90.6</td>\n",
              "      <td>35.4</td>\n",
              "      <td>669.1</td>\n",
              "      <td>6.7</td>\n",
              "      <td>18.0</td>\n",
              "      <td>33</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>oct</td>\n",
              "      <td>sat</td>\n",
              "      <td>90.6</td>\n",
              "      <td>43.7</td>\n",
              "      <td>686.9</td>\n",
              "      <td>6.7</td>\n",
              "      <td>14.6</td>\n",
              "      <td>33</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>mar</td>\n",
              "      <td>fri</td>\n",
              "      <td>91.7</td>\n",
              "      <td>33.3</td>\n",
              "      <td>77.5</td>\n",
              "      <td>9.0</td>\n",
              "      <td>8.3</td>\n",
              "      <td>97</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>mar</td>\n",
              "      <td>sun</td>\n",
              "      <td>89.3</td>\n",
              "      <td>51.3</td>\n",
              "      <td>102.2</td>\n",
              "      <td>9.6</td>\n",
              "      <td>11.4</td>\n",
              "      <td>99</td>\n",
              "      <td>1.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  month  day  FFMC   DMC  ...  monthnov  monthoct  monthsep  size_category\n",
              "0   mar  fri  86.2  26.2  ...         0         0         0              1\n",
              "1   oct  tue  90.6  35.4  ...         0         1         0              1\n",
              "2   oct  sat  90.6  43.7  ...         0         1         0              1\n",
              "3   mar  fri  91.7  33.3  ...         0         0         0              1\n",
              "4   mar  sun  89.3  51.3  ...         0         0         0              1\n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "cec7d713",
        "outputId": "a8f427e1-08ab-4c3a-e3b9-b2c195438bc9"
      },
      "source": [
        "df.describe()"
      ],
      "id": "cec7d713",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>FFMC</th>\n",
              "      <th>DMC</th>\n",
              "      <th>DC</th>\n",
              "      <th>ISI</th>\n",
              "      <th>temp</th>\n",
              "      <th>RH</th>\n",
              "      <th>wind</th>\n",
              "      <th>rain</th>\n",
              "      <th>area</th>\n",
              "      <th>dayfri</th>\n",
              "      <th>daymon</th>\n",
              "      <th>daysat</th>\n",
              "      <th>daysun</th>\n",
              "      <th>daythu</th>\n",
              "      <th>daytue</th>\n",
              "      <th>daywed</th>\n",
              "      <th>monthapr</th>\n",
              "      <th>monthaug</th>\n",
              "      <th>monthdec</th>\n",
              "      <th>monthfeb</th>\n",
              "      <th>monthjan</th>\n",
              "      <th>monthjul</th>\n",
              "      <th>monthjun</th>\n",
              "      <th>monthmar</th>\n",
              "      <th>monthmay</th>\n",
              "      <th>monthnov</th>\n",
              "      <th>monthoct</th>\n",
              "      <th>monthsep</th>\n",
              "      <th>size_category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>90.644681</td>\n",
              "      <td>110.872340</td>\n",
              "      <td>547.940039</td>\n",
              "      <td>9.021663</td>\n",
              "      <td>18.889168</td>\n",
              "      <td>44.288201</td>\n",
              "      <td>4.017602</td>\n",
              "      <td>0.021663</td>\n",
              "      <td>12.847292</td>\n",
              "      <td>0.164410</td>\n",
              "      <td>0.143133</td>\n",
              "      <td>0.162476</td>\n",
              "      <td>0.183752</td>\n",
              "      <td>0.117988</td>\n",
              "      <td>0.123791</td>\n",
              "      <td>0.104449</td>\n",
              "      <td>0.017408</td>\n",
              "      <td>0.355899</td>\n",
              "      <td>0.017408</td>\n",
              "      <td>0.038685</td>\n",
              "      <td>0.003868</td>\n",
              "      <td>0.061896</td>\n",
              "      <td>0.032882</td>\n",
              "      <td>0.104449</td>\n",
              "      <td>0.003868</td>\n",
              "      <td>0.001934</td>\n",
              "      <td>0.029014</td>\n",
              "      <td>0.332689</td>\n",
              "      <td>1.268859</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>5.520111</td>\n",
              "      <td>64.046482</td>\n",
              "      <td>248.066192</td>\n",
              "      <td>4.559477</td>\n",
              "      <td>5.806625</td>\n",
              "      <td>16.317469</td>\n",
              "      <td>1.791653</td>\n",
              "      <td>0.295959</td>\n",
              "      <td>63.655818</td>\n",
              "      <td>0.371006</td>\n",
              "      <td>0.350548</td>\n",
              "      <td>0.369244</td>\n",
              "      <td>0.387657</td>\n",
              "      <td>0.322907</td>\n",
              "      <td>0.329662</td>\n",
              "      <td>0.306138</td>\n",
              "      <td>0.130913</td>\n",
              "      <td>0.479249</td>\n",
              "      <td>0.130913</td>\n",
              "      <td>0.193029</td>\n",
              "      <td>0.062137</td>\n",
              "      <td>0.241199</td>\n",
              "      <td>0.178500</td>\n",
              "      <td>0.306138</td>\n",
              "      <td>0.062137</td>\n",
              "      <td>0.043980</td>\n",
              "      <td>0.168007</td>\n",
              "      <td>0.471632</td>\n",
              "      <td>0.443796</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>18.700000</td>\n",
              "      <td>1.100000</td>\n",
              "      <td>7.900000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.200000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>90.200000</td>\n",
              "      <td>68.600000</td>\n",
              "      <td>437.700000</td>\n",
              "      <td>6.500000</td>\n",
              "      <td>15.500000</td>\n",
              "      <td>33.000000</td>\n",
              "      <td>2.700000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>91.600000</td>\n",
              "      <td>108.300000</td>\n",
              "      <td>664.200000</td>\n",
              "      <td>8.400000</td>\n",
              "      <td>19.300000</td>\n",
              "      <td>42.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.520000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>92.900000</td>\n",
              "      <td>142.400000</td>\n",
              "      <td>713.900000</td>\n",
              "      <td>10.800000</td>\n",
              "      <td>22.800000</td>\n",
              "      <td>53.000000</td>\n",
              "      <td>4.900000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.570000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>96.200000</td>\n",
              "      <td>291.300000</td>\n",
              "      <td>860.600000</td>\n",
              "      <td>56.100000</td>\n",
              "      <td>33.300000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>9.400000</td>\n",
              "      <td>6.400000</td>\n",
              "      <td>1090.840000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             FFMC         DMC  ...    monthsep  size_category\n",
              "count  517.000000  517.000000  ...  517.000000     517.000000\n",
              "mean    90.644681  110.872340  ...    0.332689       1.268859\n",
              "std      5.520111   64.046482  ...    0.471632       0.443796\n",
              "min     18.700000    1.100000  ...    0.000000       1.000000\n",
              "25%     90.200000   68.600000  ...    0.000000       1.000000\n",
              "50%     91.600000  108.300000  ...    0.000000       1.000000\n",
              "75%     92.900000  142.400000  ...    1.000000       2.000000\n",
              "max     96.200000  291.300000  ...    1.000000       2.000000\n",
              "\n",
              "[8 rows x 29 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "720c43f9",
        "outputId": "31211fb9-7c59-4a05-c3a8-6f70cfc6808b"
      },
      "source": [
        "df.info()"
      ],
      "id": "720c43f9",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 517 entries, 0 to 516\n",
            "Data columns (total 31 columns):\n",
            " #   Column         Non-Null Count  Dtype  \n",
            "---  ------         --------------  -----  \n",
            " 0   month          517 non-null    object \n",
            " 1   day            517 non-null    object \n",
            " 2   FFMC           517 non-null    float64\n",
            " 3   DMC            517 non-null    float64\n",
            " 4   DC             517 non-null    float64\n",
            " 5   ISI            517 non-null    float64\n",
            " 6   temp           517 non-null    float64\n",
            " 7   RH             517 non-null    int64  \n",
            " 8   wind           517 non-null    float64\n",
            " 9   rain           517 non-null    float64\n",
            " 10  area           517 non-null    float64\n",
            " 11  dayfri         517 non-null    int64  \n",
            " 12  daymon         517 non-null    int64  \n",
            " 13  daysat         517 non-null    int64  \n",
            " 14  daysun         517 non-null    int64  \n",
            " 15  daythu         517 non-null    int64  \n",
            " 16  daytue         517 non-null    int64  \n",
            " 17  daywed         517 non-null    int64  \n",
            " 18  monthapr       517 non-null    int64  \n",
            " 19  monthaug       517 non-null    int64  \n",
            " 20  monthdec       517 non-null    int64  \n",
            " 21  monthfeb       517 non-null    int64  \n",
            " 22  monthjan       517 non-null    int64  \n",
            " 23  monthjul       517 non-null    int64  \n",
            " 24  monthjun       517 non-null    int64  \n",
            " 25  monthmar       517 non-null    int64  \n",
            " 26  monthmay       517 non-null    int64  \n",
            " 27  monthnov       517 non-null    int64  \n",
            " 28  monthoct       517 non-null    int64  \n",
            " 29  monthsep       517 non-null    int64  \n",
            " 30  size_category  517 non-null    int64  \n",
            "dtypes: float64(8), int64(21), object(2)\n",
            "memory usage: 125.3+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ab2f7f88",
        "outputId": "40d32051-4969-4d89-8021-21dae8c8eb2e"
      },
      "source": [
        "#we can see that there are no missing values\n",
        "df.isnull().sum()"
      ],
      "id": "ab2f7f88",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "month            0\n",
              "day              0\n",
              "FFMC             0\n",
              "DMC              0\n",
              "DC               0\n",
              "ISI              0\n",
              "temp             0\n",
              "RH               0\n",
              "wind             0\n",
              "rain             0\n",
              "area             0\n",
              "dayfri           0\n",
              "daymon           0\n",
              "daysat           0\n",
              "daysun           0\n",
              "daythu           0\n",
              "daytue           0\n",
              "daywed           0\n",
              "monthapr         0\n",
              "monthaug         0\n",
              "monthdec         0\n",
              "monthfeb         0\n",
              "monthjan         0\n",
              "monthjul         0\n",
              "monthjun         0\n",
              "monthmar         0\n",
              "monthmay         0\n",
              "monthnov         0\n",
              "monthoct         0\n",
              "monthsep         0\n",
              "size_category    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "53b58f95",
        "outputId": "4201789f-9897-4969-e530-13d5b5f70f70"
      },
      "source": [
        "df.head()"
      ],
      "id": "53b58f95",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>month</th>\n",
              "      <th>day</th>\n",
              "      <th>FFMC</th>\n",
              "      <th>DMC</th>\n",
              "      <th>DC</th>\n",
              "      <th>ISI</th>\n",
              "      <th>temp</th>\n",
              "      <th>RH</th>\n",
              "      <th>wind</th>\n",
              "      <th>rain</th>\n",
              "      <th>area</th>\n",
              "      <th>dayfri</th>\n",
              "      <th>daymon</th>\n",
              "      <th>daysat</th>\n",
              "      <th>daysun</th>\n",
              "      <th>daythu</th>\n",
              "      <th>daytue</th>\n",
              "      <th>daywed</th>\n",
              "      <th>monthapr</th>\n",
              "      <th>monthaug</th>\n",
              "      <th>monthdec</th>\n",
              "      <th>monthfeb</th>\n",
              "      <th>monthjan</th>\n",
              "      <th>monthjul</th>\n",
              "      <th>monthjun</th>\n",
              "      <th>monthmar</th>\n",
              "      <th>monthmay</th>\n",
              "      <th>monthnov</th>\n",
              "      <th>monthoct</th>\n",
              "      <th>monthsep</th>\n",
              "      <th>size_category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>mar</td>\n",
              "      <td>fri</td>\n",
              "      <td>86.2</td>\n",
              "      <td>26.2</td>\n",
              "      <td>94.3</td>\n",
              "      <td>5.1</td>\n",
              "      <td>8.2</td>\n",
              "      <td>51</td>\n",
              "      <td>6.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>oct</td>\n",
              "      <td>tue</td>\n",
              "      <td>90.6</td>\n",
              "      <td>35.4</td>\n",
              "      <td>669.1</td>\n",
              "      <td>6.7</td>\n",
              "      <td>18.0</td>\n",
              "      <td>33</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>oct</td>\n",
              "      <td>sat</td>\n",
              "      <td>90.6</td>\n",
              "      <td>43.7</td>\n",
              "      <td>686.9</td>\n",
              "      <td>6.7</td>\n",
              "      <td>14.6</td>\n",
              "      <td>33</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>mar</td>\n",
              "      <td>fri</td>\n",
              "      <td>91.7</td>\n",
              "      <td>33.3</td>\n",
              "      <td>77.5</td>\n",
              "      <td>9.0</td>\n",
              "      <td>8.3</td>\n",
              "      <td>97</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>mar</td>\n",
              "      <td>sun</td>\n",
              "      <td>89.3</td>\n",
              "      <td>51.3</td>\n",
              "      <td>102.2</td>\n",
              "      <td>9.6</td>\n",
              "      <td>11.4</td>\n",
              "      <td>99</td>\n",
              "      <td>1.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  month  day  FFMC   DMC  ...  monthnov  monthoct  monthsep  size_category\n",
              "0   mar  fri  86.2  26.2  ...         0         0         0              1\n",
              "1   oct  tue  90.6  35.4  ...         0         1         0              1\n",
              "2   oct  sat  90.6  43.7  ...         0         1         0              1\n",
              "3   mar  fri  91.7  33.3  ...         0         0         0              1\n",
              "4   mar  sun  89.3  51.3  ...         0         0         0              1\n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "id": "8fc8a398",
        "outputId": "c61b1851-9c96-45ea-eb09-d6a001df8a8f"
      },
      "source": [
        "#dropping month and day column as they are alrady seperatly given in the data \n",
        "df1 = df.drop(['month','day'],axis=1)\n",
        "df1"
      ],
      "id": "8fc8a398",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>FFMC</th>\n",
              "      <th>DMC</th>\n",
              "      <th>DC</th>\n",
              "      <th>ISI</th>\n",
              "      <th>temp</th>\n",
              "      <th>RH</th>\n",
              "      <th>wind</th>\n",
              "      <th>rain</th>\n",
              "      <th>area</th>\n",
              "      <th>dayfri</th>\n",
              "      <th>daymon</th>\n",
              "      <th>daysat</th>\n",
              "      <th>daysun</th>\n",
              "      <th>daythu</th>\n",
              "      <th>daytue</th>\n",
              "      <th>daywed</th>\n",
              "      <th>monthapr</th>\n",
              "      <th>monthaug</th>\n",
              "      <th>monthdec</th>\n",
              "      <th>monthfeb</th>\n",
              "      <th>monthjan</th>\n",
              "      <th>monthjul</th>\n",
              "      <th>monthjun</th>\n",
              "      <th>monthmar</th>\n",
              "      <th>monthmay</th>\n",
              "      <th>monthnov</th>\n",
              "      <th>monthoct</th>\n",
              "      <th>monthsep</th>\n",
              "      <th>size_category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>86.2</td>\n",
              "      <td>26.2</td>\n",
              "      <td>94.3</td>\n",
              "      <td>5.1</td>\n",
              "      <td>8.2</td>\n",
              "      <td>51</td>\n",
              "      <td>6.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>90.6</td>\n",
              "      <td>35.4</td>\n",
              "      <td>669.1</td>\n",
              "      <td>6.7</td>\n",
              "      <td>18.0</td>\n",
              "      <td>33</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>90.6</td>\n",
              "      <td>43.7</td>\n",
              "      <td>686.9</td>\n",
              "      <td>6.7</td>\n",
              "      <td>14.6</td>\n",
              "      <td>33</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>91.7</td>\n",
              "      <td>33.3</td>\n",
              "      <td>77.5</td>\n",
              "      <td>9.0</td>\n",
              "      <td>8.3</td>\n",
              "      <td>97</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>89.3</td>\n",
              "      <td>51.3</td>\n",
              "      <td>102.2</td>\n",
              "      <td>9.6</td>\n",
              "      <td>11.4</td>\n",
              "      <td>99</td>\n",
              "      <td>1.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>512</th>\n",
              "      <td>81.6</td>\n",
              "      <td>56.7</td>\n",
              "      <td>665.6</td>\n",
              "      <td>1.9</td>\n",
              "      <td>27.8</td>\n",
              "      <td>32</td>\n",
              "      <td>2.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.44</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>513</th>\n",
              "      <td>81.6</td>\n",
              "      <td>56.7</td>\n",
              "      <td>665.6</td>\n",
              "      <td>1.9</td>\n",
              "      <td>21.9</td>\n",
              "      <td>71</td>\n",
              "      <td>5.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>54.29</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>514</th>\n",
              "      <td>81.6</td>\n",
              "      <td>56.7</td>\n",
              "      <td>665.6</td>\n",
              "      <td>1.9</td>\n",
              "      <td>21.2</td>\n",
              "      <td>70</td>\n",
              "      <td>6.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.16</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>515</th>\n",
              "      <td>94.4</td>\n",
              "      <td>146.0</td>\n",
              "      <td>614.7</td>\n",
              "      <td>11.3</td>\n",
              "      <td>25.6</td>\n",
              "      <td>42</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>516</th>\n",
              "      <td>79.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>106.7</td>\n",
              "      <td>1.1</td>\n",
              "      <td>11.8</td>\n",
              "      <td>31</td>\n",
              "      <td>4.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>517 rows × 29 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     FFMC    DMC     DC   ISI  ...  monthnov  monthoct  monthsep  size_category\n",
              "0    86.2   26.2   94.3   5.1  ...         0         0         0              1\n",
              "1    90.6   35.4  669.1   6.7  ...         0         1         0              1\n",
              "2    90.6   43.7  686.9   6.7  ...         0         1         0              1\n",
              "3    91.7   33.3   77.5   9.0  ...         0         0         0              1\n",
              "4    89.3   51.3  102.2   9.6  ...         0         0         0              1\n",
              "..    ...    ...    ...   ...  ...       ...       ...       ...            ...\n",
              "512  81.6   56.7  665.6   1.9  ...         0         0         0              2\n",
              "513  81.6   56.7  665.6   1.9  ...         0         0         0              2\n",
              "514  81.6   56.7  665.6   1.9  ...         0         0         0              2\n",
              "515  94.4  146.0  614.7  11.3  ...         0         0         0              1\n",
              "516  79.5    3.0  106.7   1.1  ...         1         0         0              1\n",
              "\n",
              "[517 rows x 29 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcf05788",
        "outputId": "3e2a74f0-328c-4d30-ac48-aeec3cd44fd8"
      },
      "source": [
        "#removing duplicates\n",
        "df1[df1.duplicated()].shape"
      ],
      "id": "fcf05788",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8, 29)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "0c0b8908",
        "outputId": "663d4f97-f4e5-4813-8193-0c513fb3c963"
      },
      "source": [
        "df1[df1.duplicated()]"
      ],
      "id": "0c0b8908",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>FFMC</th>\n",
              "      <th>DMC</th>\n",
              "      <th>DC</th>\n",
              "      <th>ISI</th>\n",
              "      <th>temp</th>\n",
              "      <th>RH</th>\n",
              "      <th>wind</th>\n",
              "      <th>rain</th>\n",
              "      <th>area</th>\n",
              "      <th>dayfri</th>\n",
              "      <th>daymon</th>\n",
              "      <th>daysat</th>\n",
              "      <th>daysun</th>\n",
              "      <th>daythu</th>\n",
              "      <th>daytue</th>\n",
              "      <th>daywed</th>\n",
              "      <th>monthapr</th>\n",
              "      <th>monthaug</th>\n",
              "      <th>monthdec</th>\n",
              "      <th>monthfeb</th>\n",
              "      <th>monthjan</th>\n",
              "      <th>monthjul</th>\n",
              "      <th>monthjun</th>\n",
              "      <th>monthmar</th>\n",
              "      <th>monthmay</th>\n",
              "      <th>monthnov</th>\n",
              "      <th>monthoct</th>\n",
              "      <th>monthsep</th>\n",
              "      <th>size_category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>92.1</td>\n",
              "      <td>111.2</td>\n",
              "      <td>654.1</td>\n",
              "      <td>9.6</td>\n",
              "      <td>20.4</td>\n",
              "      <td>42</td>\n",
              "      <td>4.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>91.4</td>\n",
              "      <td>142.4</td>\n",
              "      <td>601.4</td>\n",
              "      <td>10.6</td>\n",
              "      <td>19.8</td>\n",
              "      <td>39</td>\n",
              "      <td>5.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>215</th>\n",
              "      <td>91.7</td>\n",
              "      <td>35.8</td>\n",
              "      <td>80.8</td>\n",
              "      <td>7.8</td>\n",
              "      <td>17.0</td>\n",
              "      <td>27</td>\n",
              "      <td>4.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>28.66</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>303</th>\n",
              "      <td>91.1</td>\n",
              "      <td>94.1</td>\n",
              "      <td>232.1</td>\n",
              "      <td>7.1</td>\n",
              "      <td>19.2</td>\n",
              "      <td>38</td>\n",
              "      <td>4.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>426</th>\n",
              "      <td>91.6</td>\n",
              "      <td>248.4</td>\n",
              "      <td>753.8</td>\n",
              "      <td>6.3</td>\n",
              "      <td>20.4</td>\n",
              "      <td>56</td>\n",
              "      <td>2.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>461</th>\n",
              "      <td>93.7</td>\n",
              "      <td>231.1</td>\n",
              "      <td>715.1</td>\n",
              "      <td>8.4</td>\n",
              "      <td>18.9</td>\n",
              "      <td>64</td>\n",
              "      <td>4.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>501</th>\n",
              "      <td>96.1</td>\n",
              "      <td>181.1</td>\n",
              "      <td>671.2</td>\n",
              "      <td>14.3</td>\n",
              "      <td>21.6</td>\n",
              "      <td>65</td>\n",
              "      <td>4.9</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>508</th>\n",
              "      <td>91.0</td>\n",
              "      <td>166.9</td>\n",
              "      <td>752.6</td>\n",
              "      <td>7.1</td>\n",
              "      <td>25.9</td>\n",
              "      <td>41</td>\n",
              "      <td>3.6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     FFMC    DMC     DC   ISI  ...  monthnov  monthoct  monthsep  size_category\n",
              "53   92.1  111.2  654.1   9.6  ...         0         0         0              1\n",
              "100  91.4  142.4  601.4  10.6  ...         0         0         0              1\n",
              "215  91.7   35.8   80.8   7.8  ...         0         0         0              2\n",
              "303  91.1   94.1  232.1   7.1  ...         0         0         0              1\n",
              "426  91.6  248.4  753.8   6.3  ...         0         0         0              1\n",
              "461  93.7  231.1  715.1   8.4  ...         0         0         0              1\n",
              "501  96.1  181.1  671.2  14.3  ...         0         0         0              1\n",
              "508  91.0  166.9  752.6   7.1  ...         0         0         0              1\n",
              "\n",
              "[8 rows x 29 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "394523fd"
      },
      "source": [
        "df2=df1.drop_duplicates()"
      ],
      "id": "394523fd",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b282b5ac",
        "outputId": "a00ae53f-2763-4e6f-80c4-1144fc0f3686"
      },
      "source": [
        "df2[df2.duplicated()].shape"
      ],
      "id": "b282b5ac",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, 29)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91ec4fff"
      },
      "source": [
        "import tensorflow\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense"
      ],
      "id": "91ec4fff",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2f703c01"
      },
      "source": [
        "array = df2.values\n",
        "X = array[:, 0:28]\n",
        "Y = array[:, 28]"
      ],
      "id": "2f703c01",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0ff4a4f"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(30, input_dim=28,  activation='relu'))\n",
        "model.add(Dense(15,  activation='relu')) \n",
        "model.add(Dense(1, activation='sigmoid')) "
      ],
      "id": "e0ff4a4f",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "163e5e76"
      },
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "id": "163e5e76",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ef5894c",
        "outputId": "11cf882b-b7f7-45d3-bf1f-84940ca8e91b"
      },
      "source": [
        "history = model.fit(X, Y, validation_split=0.33, epochs=250, batch_size=10)"
      ],
      "id": "1ef5894c",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/250\n",
            "35/35 [==============================] - 1s 7ms/step - loss: 0.3684 - accuracy: 0.5777 - val_loss: -28.4133 - val_accuracy: 0.6726\n",
            "Epoch 2/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -28.5904 - accuracy: 0.7566 - val_loss: -60.5722 - val_accuracy: 0.6726\n",
            "Epoch 3/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -56.1025 - accuracy: 0.7566 - val_loss: -121.8435 - val_accuracy: 0.6726\n",
            "Epoch 4/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -113.6209 - accuracy: 0.7566 - val_loss: -236.3336 - val_accuracy: 0.6726\n",
            "Epoch 5/250\n",
            "35/35 [==============================] - 0s 3ms/step - loss: -202.9010 - accuracy: 0.7566 - val_loss: -429.4892 - val_accuracy: 0.6726\n",
            "Epoch 6/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -358.1546 - accuracy: 0.7566 - val_loss: -737.7955 - val_accuracy: 0.6726\n",
            "Epoch 7/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -605.0201 - accuracy: 0.7566 - val_loss: -1206.8951 - val_accuracy: 0.6726\n",
            "Epoch 8/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -980.8747 - accuracy: 0.7566 - val_loss: -1893.6302 - val_accuracy: 0.6726\n",
            "Epoch 9/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -1532.0122 - accuracy: 0.7566 - val_loss: -2883.7695 - val_accuracy: 0.6726\n",
            "Epoch 10/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -2219.3162 - accuracy: 0.7566 - val_loss: -4153.8633 - val_accuracy: 0.6726\n",
            "Epoch 11/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -3153.7346 - accuracy: 0.7566 - val_loss: -5737.3560 - val_accuracy: 0.6726\n",
            "Epoch 12/250\n",
            "35/35 [==============================] - 0s 4ms/step - loss: -4316.7642 - accuracy: 0.7566 - val_loss: -7864.6978 - val_accuracy: 0.6726\n",
            "Epoch 13/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -5794.6978 - accuracy: 0.7566 - val_loss: -10457.5518 - val_accuracy: 0.6726\n",
            "Epoch 14/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -7640.0537 - accuracy: 0.7566 - val_loss: -13522.3018 - val_accuracy: 0.6726\n",
            "Epoch 15/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -9770.3193 - accuracy: 0.7566 - val_loss: -17105.3086 - val_accuracy: 0.6726\n",
            "Epoch 16/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -12198.7480 - accuracy: 0.7566 - val_loss: -21323.9883 - val_accuracy: 0.6726\n",
            "Epoch 17/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -15206.9941 - accuracy: 0.7566 - val_loss: -26141.5098 - val_accuracy: 0.6726\n",
            "Epoch 18/250\n",
            "35/35 [==============================] - 0s 3ms/step - loss: -18421.1602 - accuracy: 0.7566 - val_loss: -31752.0684 - val_accuracy: 0.6726\n",
            "Epoch 19/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -22160.6152 - accuracy: 0.7566 - val_loss: -37935.6367 - val_accuracy: 0.6726\n",
            "Epoch 20/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -26358.7305 - accuracy: 0.7566 - val_loss: -44971.7891 - val_accuracy: 0.6726\n",
            "Epoch 21/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -31306.8125 - accuracy: 0.7566 - val_loss: -53287.8945 - val_accuracy: 0.6726\n",
            "Epoch 22/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -36589.5586 - accuracy: 0.7566 - val_loss: -61748.2266 - val_accuracy: 0.6726\n",
            "Epoch 23/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -42310.2656 - accuracy: 0.7566 - val_loss: -70908.9375 - val_accuracy: 0.6726\n",
            "Epoch 24/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -48465.4688 - accuracy: 0.7566 - val_loss: -81323.2422 - val_accuracy: 0.6726\n",
            "Epoch 25/250\n",
            "35/35 [==============================] - 0s 3ms/step - loss: -55616.0586 - accuracy: 0.7566 - val_loss: -93084.7188 - val_accuracy: 0.6726\n",
            "Epoch 26/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -62875.5352 - accuracy: 0.7566 - val_loss: -104452.9531 - val_accuracy: 0.6726\n",
            "Epoch 27/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -70647.5000 - accuracy: 0.7566 - val_loss: -116195.9375 - val_accuracy: 0.6726\n",
            "Epoch 28/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -79177.5547 - accuracy: 0.7566 - val_loss: -130882.7969 - val_accuracy: 0.6726\n",
            "Epoch 29/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -88173.5391 - accuracy: 0.7566 - val_loss: -144685.5625 - val_accuracy: 0.6726\n",
            "Epoch 30/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -98014.0938 - accuracy: 0.7566 - val_loss: -161406.8906 - val_accuracy: 0.6726\n",
            "Epoch 31/250\n",
            "35/35 [==============================] - 0s 3ms/step - loss: -107935.0703 - accuracy: 0.7566 - val_loss: -177170.4531 - val_accuracy: 0.6726\n",
            "Epoch 32/250\n",
            "35/35 [==============================] - 0s 3ms/step - loss: -118321.7969 - accuracy: 0.7566 - val_loss: -193511.7969 - val_accuracy: 0.6726\n",
            "Epoch 33/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -129250.9688 - accuracy: 0.7566 - val_loss: -211424.7656 - val_accuracy: 0.6726\n",
            "Epoch 34/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -141060.7344 - accuracy: 0.7566 - val_loss: -230304.8594 - val_accuracy: 0.6726\n",
            "Epoch 35/250\n",
            "35/35 [==============================] - 0s 3ms/step - loss: -153387.5312 - accuracy: 0.7566 - val_loss: -250921.9219 - val_accuracy: 0.6726\n",
            "Epoch 36/250\n",
            "35/35 [==============================] - 0s 3ms/step - loss: -166830.0469 - accuracy: 0.7566 - val_loss: -272693.5000 - val_accuracy: 0.6726\n",
            "Epoch 37/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -180693.5312 - accuracy: 0.7566 - val_loss: -295130.0625 - val_accuracy: 0.6726\n",
            "Epoch 38/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -196392.9688 - accuracy: 0.7566 - val_loss: -319228.6562 - val_accuracy: 0.6726\n",
            "Epoch 39/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -212931.9219 - accuracy: 0.7566 - val_loss: -345334.5938 - val_accuracy: 0.6726\n",
            "Epoch 40/250\n",
            "35/35 [==============================] - 0s 3ms/step - loss: -228856.6562 - accuracy: 0.7566 - val_loss: -370006.9375 - val_accuracy: 0.6726\n",
            "Epoch 41/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -245081.4375 - accuracy: 0.7566 - val_loss: -396148.5625 - val_accuracy: 0.6726\n",
            "Epoch 42/250\n",
            "35/35 [==============================] - 0s 3ms/step - loss: -263466.0000 - accuracy: 0.7566 - val_loss: -426031.6562 - val_accuracy: 0.6726\n",
            "Epoch 43/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -282319.2812 - accuracy: 0.7566 - val_loss: -458111.5625 - val_accuracy: 0.6726\n",
            "Epoch 44/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -301300.3438 - accuracy: 0.7566 - val_loss: -486808.4375 - val_accuracy: 0.6726\n",
            "Epoch 45/250\n",
            "35/35 [==============================] - 0s 3ms/step - loss: -321690.9375 - accuracy: 0.7566 - val_loss: -518943.6562 - val_accuracy: 0.6726\n",
            "Epoch 46/250\n",
            "35/35 [==============================] - 0s 3ms/step - loss: -342750.5938 - accuracy: 0.7566 - val_loss: -552435.3125 - val_accuracy: 0.6726\n",
            "Epoch 47/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -363013.4375 - accuracy: 0.7566 - val_loss: -583949.6250 - val_accuracy: 0.6726\n",
            "Epoch 48/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -383561.1875 - accuracy: 0.7566 - val_loss: -616121.9375 - val_accuracy: 0.6726\n",
            "Epoch 49/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -404722.5312 - accuracy: 0.7566 - val_loss: -649770.3125 - val_accuracy: 0.6726\n",
            "Epoch 50/250\n",
            "35/35 [==============================] - 0s 3ms/step - loss: -426729.2812 - accuracy: 0.7566 - val_loss: -685730.7500 - val_accuracy: 0.6726\n",
            "Epoch 51/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -451546.2812 - accuracy: 0.7566 - val_loss: -725146.1875 - val_accuracy: 0.6726\n",
            "Epoch 52/250\n",
            "35/35 [==============================] - 0s 3ms/step - loss: -475679.0938 - accuracy: 0.7566 - val_loss: -762202.0000 - val_accuracy: 0.6726\n",
            "Epoch 53/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -499494.1875 - accuracy: 0.7566 - val_loss: -801745.5000 - val_accuracy: 0.6726\n",
            "Epoch 54/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -524501.4375 - accuracy: 0.7566 - val_loss: -842584.0000 - val_accuracy: 0.6726\n",
            "Epoch 55/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -551240.2500 - accuracy: 0.7566 - val_loss: -880788.1250 - val_accuracy: 0.6726\n",
            "Epoch 56/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -579162.5000 - accuracy: 0.7566 - val_loss: -925199.6250 - val_accuracy: 0.6726\n",
            "Epoch 57/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -606726.6875 - accuracy: 0.7566 - val_loss: -970955.8750 - val_accuracy: 0.6726\n",
            "Epoch 58/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -635299.5625 - accuracy: 0.7566 - val_loss: -1017304.3750 - val_accuracy: 0.6726\n",
            "Epoch 59/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -665034.8750 - accuracy: 0.7566 - val_loss: -1063413.3750 - val_accuracy: 0.6726\n",
            "Epoch 60/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -695073.6875 - accuracy: 0.7566 - val_loss: -1111981.6250 - val_accuracy: 0.6726\n",
            "Epoch 61/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -728740.8125 - accuracy: 0.7566 - val_loss: -1165481.8750 - val_accuracy: 0.6726\n",
            "Epoch 62/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -761263.5625 - accuracy: 0.7566 - val_loss: -1216077.0000 - val_accuracy: 0.6726\n",
            "Epoch 63/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -796233.1250 - accuracy: 0.7566 - val_loss: -1272001.0000 - val_accuracy: 0.6726\n",
            "Epoch 64/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -829974.5000 - accuracy: 0.7566 - val_loss: -1325561.5000 - val_accuracy: 0.6726\n",
            "Epoch 65/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -864869.6250 - accuracy: 0.7566 - val_loss: -1376681.0000 - val_accuracy: 0.6726\n",
            "Epoch 66/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -900427.6250 - accuracy: 0.7566 - val_loss: -1432771.6250 - val_accuracy: 0.6726\n",
            "Epoch 67/250\n",
            "35/35 [==============================] - 0s 3ms/step - loss: -935750.5625 - accuracy: 0.7566 - val_loss: -1493799.0000 - val_accuracy: 0.6726\n",
            "Epoch 68/250\n",
            "35/35 [==============================] - 0s 3ms/step - loss: -973858.4375 - accuracy: 0.7566 - val_loss: -1550743.6250 - val_accuracy: 0.6726\n",
            "Epoch 69/250\n",
            "35/35 [==============================] - 0s 3ms/step - loss: -1011587.6875 - accuracy: 0.7566 - val_loss: -1610848.0000 - val_accuracy: 0.6726\n",
            "Epoch 70/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -1050330.8750 - accuracy: 0.7566 - val_loss: -1673394.5000 - val_accuracy: 0.6726\n",
            "Epoch 71/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -1090416.5000 - accuracy: 0.7566 - val_loss: -1736075.2500 - val_accuracy: 0.6726\n",
            "Epoch 72/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -1131696.0000 - accuracy: 0.7566 - val_loss: -1797834.2500 - val_accuracy: 0.6726\n",
            "Epoch 73/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -1171510.0000 - accuracy: 0.7566 - val_loss: -1866805.0000 - val_accuracy: 0.6726\n",
            "Epoch 74/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -1215311.0000 - accuracy: 0.7566 - val_loss: -1932566.5000 - val_accuracy: 0.6726\n",
            "Epoch 75/250\n",
            "35/35 [==============================] - 0s 3ms/step - loss: -1258236.1250 - accuracy: 0.7566 - val_loss: -2001635.7500 - val_accuracy: 0.6726\n",
            "Epoch 76/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -1302968.2500 - accuracy: 0.7566 - val_loss: -2071519.2500 - val_accuracy: 0.6726\n",
            "Epoch 77/250\n",
            "35/35 [==============================] - 0s 3ms/step - loss: -1348091.8750 - accuracy: 0.7566 - val_loss: -2143954.7500 - val_accuracy: 0.6726\n",
            "Epoch 78/250\n",
            "35/35 [==============================] - 0s 3ms/step - loss: -1394861.8750 - accuracy: 0.7566 - val_loss: -2216777.0000 - val_accuracy: 0.6726\n",
            "Epoch 79/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -1443360.2500 - accuracy: 0.7566 - val_loss: -2295840.5000 - val_accuracy: 0.6726\n",
            "Epoch 80/250\n",
            "35/35 [==============================] - 0s 3ms/step - loss: -1495683.0000 - accuracy: 0.7566 - val_loss: -2374018.0000 - val_accuracy: 0.6726\n",
            "Epoch 81/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -1544594.1250 - accuracy: 0.7566 - val_loss: -2455030.5000 - val_accuracy: 0.6726\n",
            "Epoch 82/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -1595769.0000 - accuracy: 0.7566 - val_loss: -2533601.2500 - val_accuracy: 0.6726\n",
            "Epoch 83/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -1647027.6250 - accuracy: 0.7566 - val_loss: -2613184.0000 - val_accuracy: 0.6726\n",
            "Epoch 84/250\n",
            "35/35 [==============================] - 0s 3ms/step - loss: -1698943.7500 - accuracy: 0.7566 - val_loss: -2694449.0000 - val_accuracy: 0.6726\n",
            "Epoch 85/250\n",
            "35/35 [==============================] - 0s 3ms/step - loss: -1751473.8750 - accuracy: 0.7566 - val_loss: -2778969.0000 - val_accuracy: 0.6726\n",
            "Epoch 86/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -1806326.3750 - accuracy: 0.7566 - val_loss: -2868910.0000 - val_accuracy: 0.6726\n",
            "Epoch 87/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -1863874.1250 - accuracy: 0.7566 - val_loss: -2958335.0000 - val_accuracy: 0.6726\n",
            "Epoch 88/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -1920022.0000 - accuracy: 0.7566 - val_loss: -3046707.7500 - val_accuracy: 0.6726\n",
            "Epoch 89/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -1977153.5000 - accuracy: 0.7566 - val_loss: -3134490.0000 - val_accuracy: 0.6726\n",
            "Epoch 90/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -2035328.7500 - accuracy: 0.7566 - val_loss: -3223967.2500 - val_accuracy: 0.6726\n",
            "Epoch 91/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -2093647.7500 - accuracy: 0.7566 - val_loss: -3319659.5000 - val_accuracy: 0.6726\n",
            "Epoch 92/250\n",
            "35/35 [==============================] - 0s 3ms/step - loss: -2154446.7500 - accuracy: 0.7566 - val_loss: -3413251.5000 - val_accuracy: 0.6726\n",
            "Epoch 93/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -2215201.7500 - accuracy: 0.7566 - val_loss: -3510937.5000 - val_accuracy: 0.6726\n",
            "Epoch 94/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -2277999.5000 - accuracy: 0.7566 - val_loss: -3607909.2500 - val_accuracy: 0.6726\n",
            "Epoch 95/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -2341967.5000 - accuracy: 0.7566 - val_loss: -3714468.5000 - val_accuracy: 0.6726\n",
            "Epoch 96/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -2407986.7500 - accuracy: 0.7566 - val_loss: -3813914.0000 - val_accuracy: 0.6726\n",
            "Epoch 97/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -2473175.0000 - accuracy: 0.7566 - val_loss: -3914846.7500 - val_accuracy: 0.6726\n",
            "Epoch 98/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -2539404.5000 - accuracy: 0.7566 - val_loss: -4017446.5000 - val_accuracy: 0.6726\n",
            "Epoch 99/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -2606082.2500 - accuracy: 0.7566 - val_loss: -4127325.0000 - val_accuracy: 0.6726\n",
            "Epoch 100/250\n",
            "35/35 [==============================] - 0s 3ms/step - loss: -2681520.7500 - accuracy: 0.7566 - val_loss: -4244204.5000 - val_accuracy: 0.6726\n",
            "Epoch 101/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -2752199.0000 - accuracy: 0.7566 - val_loss: -4352038.0000 - val_accuracy: 0.6726\n",
            "Epoch 102/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -2821139.5000 - accuracy: 0.7566 - val_loss: -4465239.0000 - val_accuracy: 0.6726\n",
            "Epoch 103/250\n",
            "35/35 [==============================] - 0s 3ms/step - loss: -2892446.2500 - accuracy: 0.7566 - val_loss: -4577213.5000 - val_accuracy: 0.6726\n",
            "Epoch 104/250\n",
            "35/35 [==============================] - 0s 3ms/step - loss: -2965212.5000 - accuracy: 0.7566 - val_loss: -4686597.5000 - val_accuracy: 0.6726\n",
            "Epoch 105/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -3036323.7500 - accuracy: 0.7566 - val_loss: -4805949.5000 - val_accuracy: 0.6726\n",
            "Epoch 106/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -3112311.2500 - accuracy: 0.7566 - val_loss: -4918412.5000 - val_accuracy: 0.6726\n",
            "Epoch 107/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -3186385.5000 - accuracy: 0.7566 - val_loss: -5037454.5000 - val_accuracy: 0.6726\n",
            "Epoch 108/250\n",
            "35/35 [==============================] - 0s 3ms/step - loss: -3261009.7500 - accuracy: 0.7566 - val_loss: -5162171.0000 - val_accuracy: 0.6726\n",
            "Epoch 109/250\n",
            "35/35 [==============================] - 0s 3ms/step - loss: -3340867.5000 - accuracy: 0.7566 - val_loss: -5274368.5000 - val_accuracy: 0.6726\n",
            "Epoch 110/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -3424413.0000 - accuracy: 0.7566 - val_loss: -5409551.0000 - val_accuracy: 0.6726\n",
            "Epoch 111/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -3504793.2500 - accuracy: 0.7566 - val_loss: -5536790.0000 - val_accuracy: 0.6726\n",
            "Epoch 112/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -3592024.2500 - accuracy: 0.7566 - val_loss: -5676837.5000 - val_accuracy: 0.6726\n",
            "Epoch 113/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -3674335.0000 - accuracy: 0.7566 - val_loss: -5802089.5000 - val_accuracy: 0.6726\n",
            "Epoch 114/250\n",
            "35/35 [==============================] - 0s 3ms/step - loss: -3753845.0000 - accuracy: 0.7566 - val_loss: -5935738.5000 - val_accuracy: 0.6726\n",
            "Epoch 115/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -3838259.7500 - accuracy: 0.7566 - val_loss: -6058676.0000 - val_accuracy: 0.6726\n",
            "Epoch 116/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -3920262.0000 - accuracy: 0.7566 - val_loss: -6191676.0000 - val_accuracy: 0.6726\n",
            "Epoch 117/250\n",
            "35/35 [==============================] - 0s 3ms/step - loss: -4005844.7500 - accuracy: 0.7566 - val_loss: -6323216.0000 - val_accuracy: 0.6726\n",
            "Epoch 118/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -4098429.0000 - accuracy: 0.7566 - val_loss: -6472392.5000 - val_accuracy: 0.6726\n",
            "Epoch 119/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -4187056.0000 - accuracy: 0.7566 - val_loss: -6612231.5000 - val_accuracy: 0.6726\n",
            "Epoch 120/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -4281288.0000 - accuracy: 0.7566 - val_loss: -6770261.5000 - val_accuracy: 0.6726\n",
            "Epoch 121/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -4373651.0000 - accuracy: 0.7566 - val_loss: -6906129.5000 - val_accuracy: 0.6726\n",
            "Epoch 122/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -4463179.5000 - accuracy: 0.7566 - val_loss: -7039073.5000 - val_accuracy: 0.6726\n",
            "Epoch 123/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -4551195.5000 - accuracy: 0.7566 - val_loss: -7184078.5000 - val_accuracy: 0.6726\n",
            "Epoch 124/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -4643990.0000 - accuracy: 0.7566 - val_loss: -7321787.5000 - val_accuracy: 0.6726\n",
            "Epoch 125/250\n",
            "35/35 [==============================] - 0s 3ms/step - loss: -4737332.0000 - accuracy: 0.7566 - val_loss: -7475066.0000 - val_accuracy: 0.6726\n",
            "Epoch 126/250\n",
            "35/35 [==============================] - 0s 3ms/step - loss: -4831554.5000 - accuracy: 0.7566 - val_loss: -7626095.0000 - val_accuracy: 0.6726\n",
            "Epoch 127/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -4927624.0000 - accuracy: 0.7566 - val_loss: -7773540.0000 - val_accuracy: 0.6726\n",
            "Epoch 128/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -5031059.0000 - accuracy: 0.7566 - val_loss: -7945242.5000 - val_accuracy: 0.6726\n",
            "Epoch 129/250\n",
            "35/35 [==============================] - 0s 3ms/step - loss: -5131623.5000 - accuracy: 0.7566 - val_loss: -8099048.5000 - val_accuracy: 0.6726\n",
            "Epoch 130/250\n",
            "35/35 [==============================] - 0s 3ms/step - loss: -5230738.5000 - accuracy: 0.7566 - val_loss: -8251179.5000 - val_accuracy: 0.6726\n",
            "Epoch 131/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -5331079.5000 - accuracy: 0.7566 - val_loss: -8401470.0000 - val_accuracy: 0.6726\n",
            "Epoch 132/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -5440839.5000 - accuracy: 0.7566 - val_loss: -8576634.0000 - val_accuracy: 0.6726\n",
            "Epoch 133/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -5541928.0000 - accuracy: 0.7566 - val_loss: -8744548.0000 - val_accuracy: 0.6726\n",
            "Epoch 134/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -5646576.0000 - accuracy: 0.7566 - val_loss: -8904139.0000 - val_accuracy: 0.6726\n",
            "Epoch 135/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -5759208.0000 - accuracy: 0.7566 - val_loss: -9086567.0000 - val_accuracy: 0.6726\n",
            "Epoch 136/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -5874033.5000 - accuracy: 0.7566 - val_loss: -9266794.0000 - val_accuracy: 0.6726\n",
            "Epoch 137/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -5980769.0000 - accuracy: 0.7566 - val_loss: -9430536.0000 - val_accuracy: 0.6726\n",
            "Epoch 138/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -6087385.5000 - accuracy: 0.7566 - val_loss: -9588735.0000 - val_accuracy: 0.6726\n",
            "Epoch 139/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -6200454.0000 - accuracy: 0.7566 - val_loss: -9782322.0000 - val_accuracy: 0.6726\n",
            "Epoch 140/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -6313824.0000 - accuracy: 0.7566 - val_loss: -9942602.0000 - val_accuracy: 0.6726\n",
            "Epoch 141/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -6420167.5000 - accuracy: 0.7566 - val_loss: -10115938.0000 - val_accuracy: 0.6726\n",
            "Epoch 142/250\n",
            "35/35 [==============================] - 0s 3ms/step - loss: -6538677.5000 - accuracy: 0.7566 - val_loss: -10310507.0000 - val_accuracy: 0.6726\n",
            "Epoch 143/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -6654481.5000 - accuracy: 0.7566 - val_loss: -10475349.0000 - val_accuracy: 0.6726\n",
            "Epoch 144/250\n",
            "35/35 [==============================] - 0s 3ms/step - loss: -6763375.0000 - accuracy: 0.7566 - val_loss: -10652387.0000 - val_accuracy: 0.6726\n",
            "Epoch 145/250\n",
            "35/35 [==============================] - 0s 3ms/step - loss: -6876578.0000 - accuracy: 0.7566 - val_loss: -10827669.0000 - val_accuracy: 0.6726\n",
            "Epoch 146/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -6989624.5000 - accuracy: 0.7566 - val_loss: -11011217.0000 - val_accuracy: 0.6726\n",
            "Epoch 147/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -7115669.5000 - accuracy: 0.7566 - val_loss: -11210163.0000 - val_accuracy: 0.6726\n",
            "Epoch 148/250\n",
            "35/35 [==============================] - 0s 3ms/step - loss: -7233570.0000 - accuracy: 0.7566 - val_loss: -11396120.0000 - val_accuracy: 0.6726\n",
            "Epoch 149/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -7360104.5000 - accuracy: 0.7566 - val_loss: -11593856.0000 - val_accuracy: 0.6726\n",
            "Epoch 150/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -7480347.0000 - accuracy: 0.7566 - val_loss: -11777573.0000 - val_accuracy: 0.6726\n",
            "Epoch 151/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -7611201.5000 - accuracy: 0.7566 - val_loss: -11976951.0000 - val_accuracy: 0.6726\n",
            "Epoch 152/250\n",
            "35/35 [==============================] - 0s 3ms/step - loss: -7731843.5000 - accuracy: 0.7566 - val_loss: -12168512.0000 - val_accuracy: 0.6726\n",
            "Epoch 153/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -7864655.5000 - accuracy: 0.7566 - val_loss: -12378034.0000 - val_accuracy: 0.6726\n",
            "Epoch 154/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -7996882.0000 - accuracy: 0.7566 - val_loss: -12592618.0000 - val_accuracy: 0.6726\n",
            "Epoch 155/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -8119056.5000 - accuracy: 0.7566 - val_loss: -12793391.0000 - val_accuracy: 0.6726\n",
            "Epoch 156/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -8244974.5000 - accuracy: 0.7566 - val_loss: -12978491.0000 - val_accuracy: 0.6726\n",
            "Epoch 157/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -8367095.0000 - accuracy: 0.7566 - val_loss: -13171355.0000 - val_accuracy: 0.6726\n",
            "Epoch 158/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -8494166.0000 - accuracy: 0.7566 - val_loss: -13353318.0000 - val_accuracy: 0.6726\n",
            "Epoch 159/250\n",
            "35/35 [==============================] - 0s 3ms/step - loss: -8628186.0000 - accuracy: 0.7566 - val_loss: -13579779.0000 - val_accuracy: 0.6726\n",
            "Epoch 160/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -8760088.0000 - accuracy: 0.7566 - val_loss: -13779799.0000 - val_accuracy: 0.6726\n",
            "Epoch 161/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -8887272.0000 - accuracy: 0.7566 - val_loss: -13988852.0000 - val_accuracy: 0.6726\n",
            "Epoch 162/250\n",
            "35/35 [==============================] - 0s 3ms/step - loss: -9018303.0000 - accuracy: 0.7566 - val_loss: -14191512.0000 - val_accuracy: 0.6726\n",
            "Epoch 163/250\n",
            "35/35 [==============================] - 0s 3ms/step - loss: -9147951.0000 - accuracy: 0.7566 - val_loss: -14402315.0000 - val_accuracy: 0.6726\n",
            "Epoch 164/250\n",
            "35/35 [==============================] - 0s 3ms/step - loss: -9283522.0000 - accuracy: 0.7566 - val_loss: -14599966.0000 - val_accuracy: 0.6726\n",
            "Epoch 165/250\n",
            "35/35 [==============================] - 0s 3ms/step - loss: -9415574.0000 - accuracy: 0.7566 - val_loss: -14809378.0000 - val_accuracy: 0.6726\n",
            "Epoch 166/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -9550519.0000 - accuracy: 0.7566 - val_loss: -15027435.0000 - val_accuracy: 0.6726\n",
            "Epoch 167/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -9699920.0000 - accuracy: 0.7566 - val_loss: -15267346.0000 - val_accuracy: 0.6726\n",
            "Epoch 168/250\n",
            "35/35 [==============================] - 0s 3ms/step - loss: -9840099.0000 - accuracy: 0.7566 - val_loss: -15489699.0000 - val_accuracy: 0.6726\n",
            "Epoch 169/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -9982670.0000 - accuracy: 0.7566 - val_loss: -15697227.0000 - val_accuracy: 0.6726\n",
            "Epoch 170/250\n",
            "35/35 [==============================] - 0s 3ms/step - loss: -10121655.0000 - accuracy: 0.7566 - val_loss: -15919614.0000 - val_accuracy: 0.6726\n",
            "Epoch 171/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -10268215.0000 - accuracy: 0.7566 - val_loss: -16150790.0000 - val_accuracy: 0.6726\n",
            "Epoch 172/250\n",
            "35/35 [==============================] - 0s 3ms/step - loss: -10417610.0000 - accuracy: 0.7566 - val_loss: -16398391.0000 - val_accuracy: 0.6726\n",
            "Epoch 173/250\n",
            "35/35 [==============================] - 0s 3ms/step - loss: -10582785.0000 - accuracy: 0.7566 - val_loss: -16641877.0000 - val_accuracy: 0.6726\n",
            "Epoch 174/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -10728181.0000 - accuracy: 0.7566 - val_loss: -16878838.0000 - val_accuracy: 0.6726\n",
            "Epoch 175/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -10874865.0000 - accuracy: 0.7566 - val_loss: -17115268.0000 - val_accuracy: 0.6726\n",
            "Epoch 176/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -11021314.0000 - accuracy: 0.7566 - val_loss: -17352788.0000 - val_accuracy: 0.6726\n",
            "Epoch 177/250\n",
            "35/35 [==============================] - 0s 3ms/step - loss: -11184274.0000 - accuracy: 0.7566 - val_loss: -17599540.0000 - val_accuracy: 0.6726\n",
            "Epoch 178/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -11337901.0000 - accuracy: 0.7566 - val_loss: -17824484.0000 - val_accuracy: 0.6726\n",
            "Epoch 179/250\n",
            "35/35 [==============================] - 0s 3ms/step - loss: -11484297.0000 - accuracy: 0.7566 - val_loss: -18070020.0000 - val_accuracy: 0.6726\n",
            "Epoch 180/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -11639865.0000 - accuracy: 0.7566 - val_loss: -18298186.0000 - val_accuracy: 0.6726\n",
            "Epoch 181/250\n",
            "35/35 [==============================] - 0s 3ms/step - loss: -11791874.0000 - accuracy: 0.7566 - val_loss: -18529850.0000 - val_accuracy: 0.6726\n",
            "Epoch 182/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -11945075.0000 - accuracy: 0.7566 - val_loss: -18782292.0000 - val_accuracy: 0.6726\n",
            "Epoch 183/250\n",
            "35/35 [==============================] - 0s 3ms/step - loss: -12101542.0000 - accuracy: 0.7566 - val_loss: -19036188.0000 - val_accuracy: 0.6726\n",
            "Epoch 184/250\n",
            "35/35 [==============================] - 0s 3ms/step - loss: -12260964.0000 - accuracy: 0.7566 - val_loss: -19285492.0000 - val_accuracy: 0.6726\n",
            "Epoch 185/250\n",
            "35/35 [==============================] - 0s 3ms/step - loss: -12420731.0000 - accuracy: 0.7566 - val_loss: -19535370.0000 - val_accuracy: 0.6726\n",
            "Epoch 186/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -12582163.0000 - accuracy: 0.7566 - val_loss: -19788326.0000 - val_accuracy: 0.6726\n",
            "Epoch 187/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -12745539.0000 - accuracy: 0.7566 - val_loss: -20044298.0000 - val_accuracy: 0.6726\n",
            "Epoch 188/250\n",
            "35/35 [==============================] - 0s 3ms/step - loss: -12923197.0000 - accuracy: 0.7566 - val_loss: -20329284.0000 - val_accuracy: 0.6726\n",
            "Epoch 189/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -13094152.0000 - accuracy: 0.7566 - val_loss: -20583100.0000 - val_accuracy: 0.6726\n",
            "Epoch 190/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -13257713.0000 - accuracy: 0.7566 - val_loss: -20854252.0000 - val_accuracy: 0.6726\n",
            "Epoch 191/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -13430867.0000 - accuracy: 0.7566 - val_loss: -21102250.0000 - val_accuracy: 0.6726\n",
            "Epoch 192/250\n",
            "35/35 [==============================] - 0s 3ms/step - loss: -13602462.0000 - accuracy: 0.7566 - val_loss: -21396728.0000 - val_accuracy: 0.6726\n",
            "Epoch 193/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -13779441.0000 - accuracy: 0.7566 - val_loss: -21665110.0000 - val_accuracy: 0.6726\n",
            "Epoch 194/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -13953134.0000 - accuracy: 0.7566 - val_loss: -21929408.0000 - val_accuracy: 0.6726\n",
            "Epoch 195/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -14124948.0000 - accuracy: 0.7566 - val_loss: -22208004.0000 - val_accuracy: 0.6726\n",
            "Epoch 196/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -14300842.0000 - accuracy: 0.7566 - val_loss: -22490096.0000 - val_accuracy: 0.6726\n",
            "Epoch 197/250\n",
            "35/35 [==============================] - 0s 3ms/step - loss: -14495839.0000 - accuracy: 0.7566 - val_loss: -22796648.0000 - val_accuracy: 0.6726\n",
            "Epoch 198/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -14678355.0000 - accuracy: 0.7566 - val_loss: -23074726.0000 - val_accuracy: 0.6726\n",
            "Epoch 199/250\n",
            "35/35 [==============================] - 0s 3ms/step - loss: -14857675.0000 - accuracy: 0.7566 - val_loss: -23349676.0000 - val_accuracy: 0.6726\n",
            "Epoch 200/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -15036404.0000 - accuracy: 0.7566 - val_loss: -23638026.0000 - val_accuracy: 0.6726\n",
            "Epoch 201/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -15232803.0000 - accuracy: 0.7566 - val_loss: -23955562.0000 - val_accuracy: 0.6726\n",
            "Epoch 202/250\n",
            "35/35 [==============================] - 0s 3ms/step - loss: -15436413.0000 - accuracy: 0.7566 - val_loss: -24272958.0000 - val_accuracy: 0.6726\n",
            "Epoch 203/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -15624898.0000 - accuracy: 0.7566 - val_loss: -24560104.0000 - val_accuracy: 0.6726\n",
            "Epoch 204/250\n",
            "35/35 [==============================] - 0s 3ms/step - loss: -15810063.0000 - accuracy: 0.7566 - val_loss: -24842846.0000 - val_accuracy: 0.6726\n",
            "Epoch 205/250\n",
            "35/35 [==============================] - 0s 3ms/step - loss: -15993551.0000 - accuracy: 0.7566 - val_loss: -25139644.0000 - val_accuracy: 0.6726\n",
            "Epoch 206/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -16180329.0000 - accuracy: 0.7566 - val_loss: -25443042.0000 - val_accuracy: 0.6726\n",
            "Epoch 207/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -16374715.0000 - accuracy: 0.7566 - val_loss: -25729466.0000 - val_accuracy: 0.6726\n",
            "Epoch 208/250\n",
            "35/35 [==============================] - 0s 3ms/step - loss: -16563589.0000 - accuracy: 0.7566 - val_loss: -26029952.0000 - val_accuracy: 0.6726\n",
            "Epoch 209/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -16757936.0000 - accuracy: 0.7566 - val_loss: -26327896.0000 - val_accuracy: 0.6726\n",
            "Epoch 210/250\n",
            "35/35 [==============================] - 0s 3ms/step - loss: -16956746.0000 - accuracy: 0.7566 - val_loss: -26650670.0000 - val_accuracy: 0.6726\n",
            "Epoch 211/250\n",
            "35/35 [==============================] - 0s 3ms/step - loss: -17173160.0000 - accuracy: 0.7566 - val_loss: -26996468.0000 - val_accuracy: 0.6726\n",
            "Epoch 212/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -17377656.0000 - accuracy: 0.7566 - val_loss: -27298794.0000 - val_accuracy: 0.6726\n",
            "Epoch 213/250\n",
            "35/35 [==============================] - 0s 3ms/step - loss: -17579450.0000 - accuracy: 0.7566 - val_loss: -27622622.0000 - val_accuracy: 0.6726\n",
            "Epoch 214/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -17779760.0000 - accuracy: 0.7566 - val_loss: -27939812.0000 - val_accuracy: 0.6726\n",
            "Epoch 215/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -17982948.0000 - accuracy: 0.7566 - val_loss: -28250948.0000 - val_accuracy: 0.6726\n",
            "Epoch 216/250\n",
            "35/35 [==============================] - 0s 3ms/step - loss: -18202682.0000 - accuracy: 0.7566 - val_loss: -28590056.0000 - val_accuracy: 0.6726\n",
            "Epoch 217/250\n",
            "35/35 [==============================] - 0s 3ms/step - loss: -18408232.0000 - accuracy: 0.7566 - val_loss: -28912226.0000 - val_accuracy: 0.6726\n",
            "Epoch 218/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -18612932.0000 - accuracy: 0.7566 - val_loss: -29231446.0000 - val_accuracy: 0.6726\n",
            "Epoch 219/250\n",
            "35/35 [==============================] - 0s 3ms/step - loss: -18817218.0000 - accuracy: 0.7566 - val_loss: -29563776.0000 - val_accuracy: 0.6726\n",
            "Epoch 220/250\n",
            "35/35 [==============================] - 0s 3ms/step - loss: -19026760.0000 - accuracy: 0.7566 - val_loss: -29887332.0000 - val_accuracy: 0.6726\n",
            "Epoch 221/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -19236634.0000 - accuracy: 0.7566 - val_loss: -30210890.0000 - val_accuracy: 0.6726\n",
            "Epoch 222/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -19443558.0000 - accuracy: 0.7566 - val_loss: -30558404.0000 - val_accuracy: 0.6726\n",
            "Epoch 223/250\n",
            "35/35 [==============================] - 0s 3ms/step - loss: -19670678.0000 - accuracy: 0.7566 - val_loss: -30937770.0000 - val_accuracy: 0.6726\n",
            "Epoch 224/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -19921460.0000 - accuracy: 0.7566 - val_loss: -31278704.0000 - val_accuracy: 0.6726\n",
            "Epoch 225/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -20130650.0000 - accuracy: 0.7566 - val_loss: -31627554.0000 - val_accuracy: 0.6726\n",
            "Epoch 226/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -20349146.0000 - accuracy: 0.7566 - val_loss: -31950372.0000 - val_accuracy: 0.6726\n",
            "Epoch 227/250\n",
            "35/35 [==============================] - 0s 3ms/step - loss: -20561598.0000 - accuracy: 0.7566 - val_loss: -32293284.0000 - val_accuracy: 0.6726\n",
            "Epoch 228/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -20798460.0000 - accuracy: 0.7566 - val_loss: -32670026.0000 - val_accuracy: 0.6726\n",
            "Epoch 229/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -21023156.0000 - accuracy: 0.7566 - val_loss: -33000566.0000 - val_accuracy: 0.6726\n",
            "Epoch 230/250\n",
            "35/35 [==============================] - 0s 3ms/step - loss: -21236864.0000 - accuracy: 0.7566 - val_loss: -33356568.0000 - val_accuracy: 0.6726\n",
            "Epoch 231/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -21460838.0000 - accuracy: 0.7566 - val_loss: -33695044.0000 - val_accuracy: 0.6726\n",
            "Epoch 232/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -21681650.0000 - accuracy: 0.7566 - val_loss: -34043432.0000 - val_accuracy: 0.6726\n",
            "Epoch 233/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -21902296.0000 - accuracy: 0.7566 - val_loss: -34414676.0000 - val_accuracy: 0.6726\n",
            "Epoch 234/250\n",
            "35/35 [==============================] - 0s 3ms/step - loss: -22157352.0000 - accuracy: 0.7566 - val_loss: -34795448.0000 - val_accuracy: 0.6726\n",
            "Epoch 235/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -22408852.0000 - accuracy: 0.7566 - val_loss: -35185848.0000 - val_accuracy: 0.6726\n",
            "Epoch 236/250\n",
            "35/35 [==============================] - 0s 3ms/step - loss: -22637764.0000 - accuracy: 0.7566 - val_loss: -35553560.0000 - val_accuracy: 0.6726\n",
            "Epoch 237/250\n",
            "35/35 [==============================] - 0s 3ms/step - loss: -22869744.0000 - accuracy: 0.7566 - val_loss: -35902156.0000 - val_accuracy: 0.6726\n",
            "Epoch 238/250\n",
            "35/35 [==============================] - 0s 3ms/step - loss: -23106478.0000 - accuracy: 0.7566 - val_loss: -36288748.0000 - val_accuracy: 0.6726\n",
            "Epoch 239/250\n",
            "35/35 [==============================] - 0s 3ms/step - loss: -23341542.0000 - accuracy: 0.7566 - val_loss: -36660480.0000 - val_accuracy: 0.6726\n",
            "Epoch 240/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -23577782.0000 - accuracy: 0.7566 - val_loss: -37015220.0000 - val_accuracy: 0.6726\n",
            "Epoch 241/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -23821778.0000 - accuracy: 0.7566 - val_loss: -37404960.0000 - val_accuracy: 0.6726\n",
            "Epoch 242/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -24070006.0000 - accuracy: 0.7566 - val_loss: -37766060.0000 - val_accuracy: 0.6726\n",
            "Epoch 243/250\n",
            "35/35 [==============================] - 0s 3ms/step - loss: -24300108.0000 - accuracy: 0.7566 - val_loss: -38166304.0000 - val_accuracy: 0.6726\n",
            "Epoch 244/250\n",
            "35/35 [==============================] - 0s 3ms/step - loss: -24544308.0000 - accuracy: 0.7566 - val_loss: -38542868.0000 - val_accuracy: 0.6726\n",
            "Epoch 245/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -24783912.0000 - accuracy: 0.7566 - val_loss: -38915492.0000 - val_accuracy: 0.6726\n",
            "Epoch 246/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -25027002.0000 - accuracy: 0.7566 - val_loss: -39289308.0000 - val_accuracy: 0.6726\n",
            "Epoch 247/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -25266870.0000 - accuracy: 0.7566 - val_loss: -39676516.0000 - val_accuracy: 0.6726\n",
            "Epoch 248/250\n",
            "35/35 [==============================] - 0s 3ms/step - loss: -25515962.0000 - accuracy: 0.7566 - val_loss: -40050780.0000 - val_accuracy: 0.6726\n",
            "Epoch 249/250\n",
            "35/35 [==============================] - 0s 3ms/step - loss: -25762844.0000 - accuracy: 0.7566 - val_loss: -40432612.0000 - val_accuracy: 0.6726\n",
            "Epoch 250/250\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -26009876.0000 - accuracy: 0.7566 - val_loss: -40834732.0000 - val_accuracy: 0.6726\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cf73cffb",
        "outputId": "25818f9d-1c75-4814-c6bf-ebc8d4abfefd"
      },
      "source": [
        "scores = model.evaluate(X, Y)\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
      ],
      "id": "cf73cffb",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "16/16 [==============================] - 0s 1ms/step - loss: -30994518.0000 - accuracy: 0.7289\n",
            "accuracy: 72.89%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cc891cfa",
        "outputId": "5e8db40d-b51e-44b5-a721-211fb9b818a2"
      },
      "source": [
        "model.metrics_names"
      ],
      "id": "cc891cfa",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['loss', 'accuracy']"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a40f2044",
        "outputId": "4d4a43e4-bf15-438b-c83b-e502b04f7856"
      },
      "source": [
        "model.history.history.keys()"
      ],
      "id": "a40f2044",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys([])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "52c07f47",
        "outputId": "970ac34e-b3ce-46e7-b7f1-b59ffaf2da5b"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "id": "52c07f47",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58cd018f"
      },
      "source": [
        "Array = df2.values\n",
        "X = Array[:, 0:28]\n",
        "Y = Array[:, 28]"
      ],
      "id": "58cd018f",
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2b0dea72"
      },
      "source": [
        "# Standardization\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "a = StandardScaler()\n",
        "a.fit(X)\n",
        "X_standardized = a.transform(X)"
      ],
      "id": "2b0dea72",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "id": "aa168fee",
        "outputId": "b7473372-5747-44ec-a698-2f3ce342a94e"
      },
      "source": [
        "pd.DataFrame(X_standardized).describe()"
      ],
      "id": "aa168fee",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>5.090000e+02</td>\n",
              "      <td>5.090000e+02</td>\n",
              "      <td>5.090000e+02</td>\n",
              "      <td>5.090000e+02</td>\n",
              "      <td>5.090000e+02</td>\n",
              "      <td>5.090000e+02</td>\n",
              "      <td>5.090000e+02</td>\n",
              "      <td>5.090000e+02</td>\n",
              "      <td>5.090000e+02</td>\n",
              "      <td>5.090000e+02</td>\n",
              "      <td>5.090000e+02</td>\n",
              "      <td>5.090000e+02</td>\n",
              "      <td>5.090000e+02</td>\n",
              "      <td>5.090000e+02</td>\n",
              "      <td>5.090000e+02</td>\n",
              "      <td>5.090000e+02</td>\n",
              "      <td>5.090000e+02</td>\n",
              "      <td>5.090000e+02</td>\n",
              "      <td>5.090000e+02</td>\n",
              "      <td>5.090000e+02</td>\n",
              "      <td>5.090000e+02</td>\n",
              "      <td>5.090000e+02</td>\n",
              "      <td>5.090000e+02</td>\n",
              "      <td>5.090000e+02</td>\n",
              "      <td>5.090000e+02</td>\n",
              "      <td>5.090000e+02</td>\n",
              "      <td>5.090000e+02</td>\n",
              "      <td>5.090000e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>-1.096700e-15</td>\n",
              "      <td>-7.852265e-18</td>\n",
              "      <td>-1.483206e-17</td>\n",
              "      <td>-8.986481e-17</td>\n",
              "      <td>1.832195e-16</td>\n",
              "      <td>1.797296e-16</td>\n",
              "      <td>2.225899e-16</td>\n",
              "      <td>-2.883526e-16</td>\n",
              "      <td>-4.765889e-17</td>\n",
              "      <td>-2.835540e-18</td>\n",
              "      <td>1.395958e-17</td>\n",
              "      <td>-7.939512e-17</td>\n",
              "      <td>1.494112e-16</td>\n",
              "      <td>-1.070962e-16</td>\n",
              "      <td>-9.248223e-17</td>\n",
              "      <td>1.317436e-16</td>\n",
              "      <td>-1.007707e-16</td>\n",
              "      <td>-4.427805e-16</td>\n",
              "      <td>-4.740805e-16</td>\n",
              "      <td>1.013160e-16</td>\n",
              "      <td>-1.374146e-17</td>\n",
              "      <td>3.177986e-16</td>\n",
              "      <td>-3.446272e-17</td>\n",
              "      <td>3.167080e-16</td>\n",
              "      <td>-1.374146e-17</td>\n",
              "      <td>4.606662e-16</td>\n",
              "      <td>7.877349e-16</td>\n",
              "      <td>2.791916e-16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.000984e+00</td>\n",
              "      <td>1.000984e+00</td>\n",
              "      <td>1.000984e+00</td>\n",
              "      <td>1.000984e+00</td>\n",
              "      <td>1.000984e+00</td>\n",
              "      <td>1.000984e+00</td>\n",
              "      <td>1.000984e+00</td>\n",
              "      <td>1.000984e+00</td>\n",
              "      <td>1.000984e+00</td>\n",
              "      <td>1.000984e+00</td>\n",
              "      <td>1.000984e+00</td>\n",
              "      <td>1.000984e+00</td>\n",
              "      <td>1.000984e+00</td>\n",
              "      <td>1.000984e+00</td>\n",
              "      <td>1.000984e+00</td>\n",
              "      <td>1.000984e+00</td>\n",
              "      <td>1.000984e+00</td>\n",
              "      <td>1.000984e+00</td>\n",
              "      <td>1.000984e+00</td>\n",
              "      <td>1.000984e+00</td>\n",
              "      <td>1.000984e+00</td>\n",
              "      <td>1.000984e+00</td>\n",
              "      <td>1.000984e+00</td>\n",
              "      <td>1.000984e+00</td>\n",
              "      <td>1.000984e+00</td>\n",
              "      <td>1.000984e+00</td>\n",
              "      <td>1.000984e+00</td>\n",
              "      <td>1.000984e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-1.295805e+01</td>\n",
              "      <td>-1.712164e+00</td>\n",
              "      <td>-2.177385e+00</td>\n",
              "      <td>-1.969965e+00</td>\n",
              "      <td>-2.855946e+00</td>\n",
              "      <td>-1.789299e+00</td>\n",
              "      <td>-2.007272e+00</td>\n",
              "      <td>-6.903477e-02</td>\n",
              "      <td>-2.027913e-01</td>\n",
              "      <td>-4.414019e-01</td>\n",
              "      <td>-4.124499e-01</td>\n",
              "      <td>-4.382208e-01</td>\n",
              "      <td>-4.759265e-01</td>\n",
              "      <td>-3.655548e-01</td>\n",
              "      <td>-3.758399e-01</td>\n",
              "      <td>-3.409224e-01</td>\n",
              "      <td>-1.341641e-01</td>\n",
              "      <td>-7.333242e-01</td>\n",
              "      <td>-1.341641e-01</td>\n",
              "      <td>-2.022370e-01</td>\n",
              "      <td>-6.280743e-02</td>\n",
              "      <td>-2.590096e-01</td>\n",
              "      <td>-1.801509e-01</td>\n",
              "      <td>-3.409224e-01</td>\n",
              "      <td>-6.280743e-02</td>\n",
              "      <td>-4.436783e-02</td>\n",
              "      <td>-1.742538e-01</td>\n",
              "      <td>-7.144129e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>-7.532785e-02</td>\n",
              "      <td>-7.520348e-01</td>\n",
              "      <td>-4.439871e-01</td>\n",
              "      <td>-5.727610e-01</td>\n",
              "      <td>-5.938679e-01</td>\n",
              "      <td>-7.494866e-01</td>\n",
              "      <td>-7.288945e-01</td>\n",
              "      <td>-6.903477e-02</td>\n",
              "      <td>-2.027913e-01</td>\n",
              "      <td>-4.414019e-01</td>\n",
              "      <td>-4.124499e-01</td>\n",
              "      <td>-4.382208e-01</td>\n",
              "      <td>-4.759265e-01</td>\n",
              "      <td>-3.655548e-01</td>\n",
              "      <td>-3.758399e-01</td>\n",
              "      <td>-3.409224e-01</td>\n",
              "      <td>-1.341641e-01</td>\n",
              "      <td>-7.333242e-01</td>\n",
              "      <td>-1.341641e-01</td>\n",
              "      <td>-2.022370e-01</td>\n",
              "      <td>-6.280743e-02</td>\n",
              "      <td>-2.590096e-01</td>\n",
              "      <td>-1.801509e-01</td>\n",
              "      <td>-3.409224e-01</td>\n",
              "      <td>-6.280743e-02</td>\n",
              "      <td>-4.436783e-02</td>\n",
              "      <td>-1.742538e-01</td>\n",
              "      <td>-7.144129e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1.769213e-01</td>\n",
              "      <td>-3.036890e-02</td>\n",
              "      <td>4.694951e-01</td>\n",
              "      <td>-1.361347e-01</td>\n",
              "      <td>7.447337e-02</td>\n",
              "      <td>-1.378325e-01</td>\n",
              "      <td>-6.333465e-03</td>\n",
              "      <td>-6.903477e-02</td>\n",
              "      <td>-1.932706e-01</td>\n",
              "      <td>-4.414019e-01</td>\n",
              "      <td>-4.124499e-01</td>\n",
              "      <td>-4.382208e-01</td>\n",
              "      <td>-4.759265e-01</td>\n",
              "      <td>-3.655548e-01</td>\n",
              "      <td>-3.758399e-01</td>\n",
              "      <td>-3.409224e-01</td>\n",
              "      <td>-1.341641e-01</td>\n",
              "      <td>-7.333242e-01</td>\n",
              "      <td>-1.341641e-01</td>\n",
              "      <td>-2.022370e-01</td>\n",
              "      <td>-6.280743e-02</td>\n",
              "      <td>-2.590096e-01</td>\n",
              "      <td>-1.801509e-01</td>\n",
              "      <td>-3.409224e-01</td>\n",
              "      <td>-6.280743e-02</td>\n",
              "      <td>-4.436783e-02</td>\n",
              "      <td>-1.742538e-01</td>\n",
              "      <td>-7.144129e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>4.111527e-01</td>\n",
              "      <td>4.873480e-01</td>\n",
              "      <td>6.699368e-01</td>\n",
              "      <td>4.314794e-01</td>\n",
              "      <td>6.742668e-01</td>\n",
              "      <td>5.349871e-01</td>\n",
              "      <td>4.939011e-01</td>\n",
              "      <td>-6.903477e-02</td>\n",
              "      <td>-1.000917e-01</td>\n",
              "      <td>-4.414019e-01</td>\n",
              "      <td>-4.124499e-01</td>\n",
              "      <td>-4.382208e-01</td>\n",
              "      <td>-4.759265e-01</td>\n",
              "      <td>-3.655548e-01</td>\n",
              "      <td>-3.758399e-01</td>\n",
              "      <td>-3.409224e-01</td>\n",
              "      <td>-1.341641e-01</td>\n",
              "      <td>1.363653e+00</td>\n",
              "      <td>-1.341641e-01</td>\n",
              "      <td>-2.022370e-01</td>\n",
              "      <td>-6.280743e-02</td>\n",
              "      <td>-2.590096e-01</td>\n",
              "      <td>-1.801509e-01</td>\n",
              "      <td>-3.409224e-01</td>\n",
              "      <td>-6.280743e-02</td>\n",
              "      <td>-4.436783e-02</td>\n",
              "      <td>-1.742538e-01</td>\n",
              "      <td>1.399751e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.005740e+00</td>\n",
              "      <td>2.840606e+00</td>\n",
              "      <td>1.261583e+00</td>\n",
              "      <td>1.027740e+01</td>\n",
              "      <td>2.473647e+00</td>\n",
              "      <td>3.409762e+00</td>\n",
              "      <td>2.995074e+00</td>\n",
              "      <td>2.155478e+01</td>\n",
              "      <td>1.682288e+01</td>\n",
              "      <td>2.265509e+00</td>\n",
              "      <td>2.424537e+00</td>\n",
              "      <td>2.281955e+00</td>\n",
              "      <td>2.101165e+00</td>\n",
              "      <td>2.735568e+00</td>\n",
              "      <td>2.660708e+00</td>\n",
              "      <td>2.933219e+00</td>\n",
              "      <td>7.453560e+00</td>\n",
              "      <td>1.363653e+00</td>\n",
              "      <td>7.453560e+00</td>\n",
              "      <td>4.944694e+00</td>\n",
              "      <td>1.592168e+01</td>\n",
              "      <td>3.860861e+00</td>\n",
              "      <td>5.550901e+00</td>\n",
              "      <td>2.933219e+00</td>\n",
              "      <td>1.592168e+01</td>\n",
              "      <td>2.253886e+01</td>\n",
              "      <td>5.738757e+00</td>\n",
              "      <td>1.399751e+00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 0             1   ...            26            27\n",
              "count  5.090000e+02  5.090000e+02  ...  5.090000e+02  5.090000e+02\n",
              "mean  -1.096700e-15 -7.852265e-18  ...  7.877349e-16  2.791916e-16\n",
              "std    1.000984e+00  1.000984e+00  ...  1.000984e+00  1.000984e+00\n",
              "min   -1.295805e+01 -1.712164e+00  ... -1.742538e-01 -7.144129e-01\n",
              "25%   -7.532785e-02 -7.520348e-01  ... -1.742538e-01 -7.144129e-01\n",
              "50%    1.769213e-01 -3.036890e-02  ... -1.742538e-01 -7.144129e-01\n",
              "75%    4.111527e-01  4.873480e-01  ... -1.742538e-01  1.399751e+00\n",
              "max    1.005740e+00  2.840606e+00  ...  5.738757e+00  1.399751e+00\n",
              "\n",
              "[8 rows x 28 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6c8e75ff"
      },
      "source": [
        "# Tuning of Hyperparameters :- Batch Size and Epochs"
      ],
      "id": "6c8e75ff"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a909c9f8"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV, KFold\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "id": "a909c9f8",
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7d3f8ce"
      },
      "source": [
        "# create model\n",
        "def create_model():\n",
        "    model = Sequential()\n",
        "    model.add(Dense(12, input_dim=28, kernel_initializer='uniform', activation='relu'))\n",
        "    model.add(Dense(8,kernel_initializer='uniform', activation='relu'))\n",
        "    model.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
        "    \n",
        "    adam=Adam(lr=0.01)\n",
        "    model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
        "    return model"
      ],
      "id": "b7d3f8ce",
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7f845a15",
        "outputId": "8e2e42f8-e348-46d9-b4dd-f360bd37d6b2"
      },
      "source": [
        "model = KerasClassifier(build_fn = create_model,verbose = 0)\n",
        "batch_size = [10,20,40]\n",
        "epochs = [10,50,100,150]\n",
        "param_grid = dict(batch_size = batch_size,epochs = epochs)\n",
        "grid = GridSearchCV(estimator = model,param_grid = param_grid,cv = KFold(),verbose = 10)\n",
        "grid_result = grid.fit(X_standardized,Y)"
      ],
      "id": "7f845a15",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
            "[CV] batch_size=10, epochs=10 ........................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ............ batch_size=10, epochs=10, score=1.000, total=   1.3s\n",
            "[CV] batch_size=10, epochs=10 ........................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.3s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ............ batch_size=10, epochs=10, score=0.824, total=   1.3s\n",
            "[CV] batch_size=10, epochs=10 ........................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    2.6s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ............ batch_size=10, epochs=10, score=0.814, total=   1.0s\n",
            "[CV] batch_size=10, epochs=10 ........................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    3.6s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ............ batch_size=10, epochs=10, score=0.863, total=   1.3s\n",
            "[CV] batch_size=10, epochs=10 ........................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    4.9s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ............ batch_size=10, epochs=10, score=0.881, total=   1.2s\n",
            "[CV] batch_size=10, epochs=50 ........................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    6.1s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ............ batch_size=10, epochs=50, score=1.000, total=   3.2s\n",
            "[CV] batch_size=10, epochs=50 ........................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    9.3s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ............ batch_size=10, epochs=50, score=0.824, total=   2.5s\n",
            "[CV] batch_size=10, epochs=50 ........................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:   11.8s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ............ batch_size=10, epochs=50, score=0.902, total=   2.6s\n",
            "[CV] batch_size=10, epochs=50 ........................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:   14.3s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ............ batch_size=10, epochs=50, score=0.931, total=   3.2s\n",
            "[CV] batch_size=10, epochs=50 ........................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:   17.5s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ............ batch_size=10, epochs=50, score=0.901, total=   3.4s\n",
            "[CV] batch_size=10, epochs=100 .......................................\n",
            "[CV] ........... batch_size=10, epochs=100, score=0.980, total=   5.7s\n",
            "[CV] batch_size=10, epochs=100 .......................................\n",
            "[CV] ........... batch_size=10, epochs=100, score=0.853, total=   5.7s\n",
            "[CV] batch_size=10, epochs=100 .......................................\n",
            "[CV] ........... batch_size=10, epochs=100, score=0.902, total=   5.7s\n",
            "[CV] batch_size=10, epochs=100 .......................................\n",
            "[CV] ........... batch_size=10, epochs=100, score=0.892, total=   5.7s\n",
            "[CV] batch_size=10, epochs=100 .......................................\n",
            "[CV] ........... batch_size=10, epochs=100, score=0.901, total=   4.5s\n",
            "[CV] batch_size=10, epochs=150 .......................................\n",
            "[CV] ........... batch_size=10, epochs=150, score=1.000, total=   6.5s\n",
            "[CV] batch_size=10, epochs=150 .......................................\n",
            "[CV] ........... batch_size=10, epochs=150, score=0.873, total=   6.3s\n",
            "[CV] batch_size=10, epochs=150 .......................................\n",
            "[CV] ........... batch_size=10, epochs=150, score=0.873, total=  10.8s\n",
            "[CV] batch_size=10, epochs=150 .......................................\n",
            "[CV] ........... batch_size=10, epochs=150, score=0.922, total=   6.3s\n",
            "[CV] batch_size=10, epochs=150 .......................................\n",
            "[CV] ........... batch_size=10, epochs=150, score=0.891, total=   6.7s\n",
            "[CV] batch_size=20, epochs=10 ........................................\n",
            "[CV] ............ batch_size=20, epochs=10, score=1.000, total=   0.8s\n",
            "[CV] batch_size=20, epochs=10 ........................................\n",
            "[CV] ............ batch_size=20, epochs=10, score=0.824, total=   0.8s\n",
            "[CV] batch_size=20, epochs=10 ........................................\n",
            "[CV] ............ batch_size=20, epochs=10, score=0.765, total=   0.9s\n",
            "[CV] batch_size=20, epochs=10 ........................................\n",
            "[CV] ............ batch_size=20, epochs=10, score=0.676, total=   0.8s\n",
            "[CV] batch_size=20, epochs=10 ........................................\n",
            "[CV] ............ batch_size=20, epochs=10, score=0.851, total=   0.9s\n",
            "[CV] batch_size=20, epochs=50 ........................................\n",
            "[CV] ............ batch_size=20, epochs=50, score=1.000, total=   1.9s\n",
            "[CV] batch_size=20, epochs=50 ........................................\n",
            "[CV] ............ batch_size=20, epochs=50, score=0.853, total=   1.7s\n",
            "[CV] batch_size=20, epochs=50 ........................................\n",
            "[CV] ............ batch_size=20, epochs=50, score=0.892, total=   1.6s\n",
            "[CV] batch_size=20, epochs=50 ........................................\n",
            "[CV] ............ batch_size=20, epochs=50, score=0.912, total=   1.9s\n",
            "[CV] batch_size=20, epochs=50 ........................................\n",
            "[CV] ............ batch_size=20, epochs=50, score=0.881, total=   1.7s\n",
            "[CV] batch_size=20, epochs=100 .......................................\n",
            "[CV] ........... batch_size=20, epochs=100, score=1.000, total=   2.7s\n",
            "[CV] batch_size=20, epochs=100 .......................................\n",
            "[CV] ........... batch_size=20, epochs=100, score=0.853, total=   3.2s\n",
            "[CV] batch_size=20, epochs=100 .......................................\n",
            "[CV] ........... batch_size=20, epochs=100, score=0.882, total=   3.2s\n",
            "[CV] batch_size=20, epochs=100 .......................................\n",
            "[CV] ........... batch_size=20, epochs=100, score=0.912, total=   2.7s\n",
            "[CV] batch_size=20, epochs=100 .......................................\n",
            "[CV] ........... batch_size=20, epochs=100, score=0.871, total=   3.2s\n",
            "[CV] batch_size=20, epochs=150 .......................................\n",
            "[CV] ........... batch_size=20, epochs=150, score=1.000, total=   3.7s\n",
            "[CV] batch_size=20, epochs=150 .......................................\n",
            "[CV] ........... batch_size=20, epochs=150, score=0.873, total=   3.7s\n",
            "[CV] batch_size=20, epochs=150 .......................................\n",
            "[CV] ........... batch_size=20, epochs=150, score=0.902, total=   5.7s\n",
            "[CV] batch_size=20, epochs=150 .......................................\n",
            "[CV] ........... batch_size=20, epochs=150, score=0.912, total=   3.7s\n",
            "[CV] batch_size=20, epochs=150 .......................................\n",
            "[CV] ........... batch_size=20, epochs=150, score=0.881, total=   4.1s\n",
            "[CV] batch_size=40, epochs=10 ........................................\n",
            "[CV] ............ batch_size=40, epochs=10, score=1.000, total=   0.8s\n",
            "[CV] batch_size=40, epochs=10 ........................................\n",
            "[CV] ............ batch_size=40, epochs=10, score=0.765, total=   0.8s\n",
            "[CV] batch_size=40, epochs=10 ........................................\n",
            "[CV] ............ batch_size=40, epochs=10, score=0.647, total=   0.7s\n",
            "[CV] batch_size=40, epochs=10 ........................................\n",
            "WARNING:tensorflow:5 out of the last 16 calls to <function Model.make_test_function.<locals>.test_function at 0x7f2801901a70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[CV] ............ batch_size=40, epochs=10, score=0.716, total=   0.8s\n",
            "[CV] batch_size=40, epochs=10 ........................................\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f28019cf5f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[CV] ............ batch_size=40, epochs=10, score=0.802, total=   0.8s\n",
            "[CV] batch_size=40, epochs=50 ........................................\n",
            "[CV] ............ batch_size=40, epochs=50, score=1.000, total=   1.9s\n",
            "[CV] batch_size=40, epochs=50 ........................................\n",
            "[CV] ............ batch_size=40, epochs=50, score=0.882, total=   1.2s\n",
            "[CV] batch_size=40, epochs=50 ........................................\n",
            "[CV] ............ batch_size=40, epochs=50, score=0.902, total=   1.2s\n",
            "[CV] batch_size=40, epochs=50 ........................................\n",
            "[CV] ............ batch_size=40, epochs=50, score=0.902, total=   1.5s\n",
            "[CV] batch_size=40, epochs=50 ........................................\n",
            "[CV] ............ batch_size=40, epochs=50, score=0.891, total=   1.2s\n",
            "[CV] batch_size=40, epochs=100 .......................................\n",
            "[CV] ........... batch_size=40, epochs=100, score=0.990, total=   1.9s\n",
            "[CV] batch_size=40, epochs=100 .......................................\n",
            "[CV] ........... batch_size=40, epochs=100, score=0.873, total=   1.9s\n",
            "[CV] batch_size=40, epochs=100 .......................................\n",
            "[CV] ........... batch_size=40, epochs=100, score=0.892, total=   1.9s\n",
            "[CV] batch_size=40, epochs=100 .......................................\n",
            "[CV] ........... batch_size=40, epochs=100, score=0.912, total=   1.8s\n",
            "[CV] batch_size=40, epochs=100 .......................................\n",
            "[CV] ........... batch_size=40, epochs=100, score=0.881, total=   1.9s\n",
            "[CV] batch_size=40, epochs=150 .......................................\n",
            "[CV] ........... batch_size=40, epochs=150, score=1.000, total=   3.2s\n",
            "[CV] batch_size=40, epochs=150 .......................................\n",
            "[CV] ........... batch_size=40, epochs=150, score=0.873, total=   3.2s\n",
            "[CV] batch_size=40, epochs=150 .......................................\n",
            "[CV] ........... batch_size=40, epochs=150, score=0.873, total=   2.3s\n",
            "[CV] batch_size=40, epochs=150 .......................................\n",
            "[CV] ........... batch_size=40, epochs=150, score=0.912, total=   3.1s\n",
            "[CV] batch_size=40, epochs=150 .......................................\n",
            "[CV] ........... batch_size=40, epochs=150, score=0.901, total=   3.5s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed:  2.8min finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e45eefc7",
        "outputId": "5d9e2626-7766-44f7-e91b-ec44449b7c79"
      },
      "source": [
        "print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "  print('{},{} with: {}'.format(mean, stdev, param))"
      ],
      "id": "e45eefc7",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best : 0.9154727220535278, using {'batch_size': 40, 'epochs': 50}\n",
            "0.8762376189231873,0.0666477376170472 with: {'batch_size': 10, 'epochs': 10}\n",
            "0.9115705728530884,0.05686372964697654 with: {'batch_size': 10, 'epochs': 50}\n",
            "0.905688214302063,0.04142944662030226 with: {'batch_size': 10, 'epochs': 100}\n",
            "0.9115511417388916,0.04771704321408688 with: {'batch_size': 10, 'epochs': 150}\n",
            "0.823238205909729,0.10677965489851961 with: {'batch_size': 20, 'epochs': 10}\n",
            "0.9076101541519165,0.04995752856315 with: {'batch_size': 20, 'epochs': 50}\n",
            "0.9036691784858704,0.051810185987564296 with: {'batch_size': 20, 'epochs': 100}\n",
            "0.9134925127029419,0.04547407669796956 with: {'batch_size': 20, 'epochs': 150}\n",
            "0.7858862400054931,0.11895663691088022 with: {'batch_size': 40, 'epochs': 10}\n",
            "0.9154727220535278,0.04289868683021893 with: {'batch_size': 40, 'epochs': 50}\n",
            "0.9095709323883057,0.04239028611197393 with: {'batch_size': 40, 'epochs': 100}\n",
            "0.9115705609321594,0.0468553385801888 with: {'batch_size': 40, 'epochs': 150}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8473ac6"
      },
      "source": [
        "# Tuning of Hyperparameters:- Learning rate and Drop out rate"
      ],
      "id": "e8473ac6"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3c657a16",
        "outputId": "bc02702e-17f4-4838-be46-7c67bc28cd85"
      },
      "source": [
        "from tensorflow.keras.layers import Dropout\n",
        "\n",
        "def create_model(learning_rate,dropout_rate):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(8,input_dim = 28,kernel_initializer = 'normal',activation = 'relu'))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(12,input_dim = 28,kernel_initializer = 'normal',activation = 'relu'))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(1,activation = 'sigmoid'))\n",
        "    \n",
        "    adam = Adam(lr = learning_rate)\n",
        "    model.compile(loss = 'binary_crossentropy',optimizer = adam,metrics = ['accuracy'])\n",
        "    return model\n",
        "\n",
        "model = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 40,epochs = 50)\n",
        "\n",
        "learning_rate = [0.001,0.01,0.1]\n",
        "dropout_rate = [0.0,0.1,0.2]\n",
        "\n",
        "param_grids = dict(learning_rate = learning_rate,dropout_rate = dropout_rate)\n",
        "\n",
        "grid = GridSearchCV(estimator = model,param_grid = param_grids,cv = KFold(),verbose = 10)\n",
        "grid_result = grid.fit(X_standardized,Y)\n"
      ],
      "id": "3c657a16",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
            "[CV] dropout_rate=0.0, learning_rate=0.001 ...........................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  dropout_rate=0.0, learning_rate=0.001, score=0.941, total=   1.2s\n",
            "[CV] dropout_rate=0.0, learning_rate=0.001 ...........................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.2s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  dropout_rate=0.0, learning_rate=0.001, score=0.765, total=   1.2s\n",
            "[CV] dropout_rate=0.0, learning_rate=0.001 ...........................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    2.5s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  dropout_rate=0.0, learning_rate=0.001, score=0.647, total=   1.3s\n",
            "[CV] dropout_rate=0.0, learning_rate=0.001 ...........................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    3.8s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  dropout_rate=0.0, learning_rate=0.001, score=0.784, total=   1.3s\n",
            "[CV] dropout_rate=0.0, learning_rate=0.001 ...........................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    5.0s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  dropout_rate=0.0, learning_rate=0.001, score=0.782, total=   1.3s\n",
            "[CV] dropout_rate=0.0, learning_rate=0.01 ............................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    6.3s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  dropout_rate=0.0, learning_rate=0.01, score=1.000, total=   1.3s\n",
            "[CV] dropout_rate=0.0, learning_rate=0.01 ............................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    7.5s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  dropout_rate=0.0, learning_rate=0.01, score=0.863, total=   1.2s\n",
            "[CV] dropout_rate=0.0, learning_rate=0.01 ............................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    8.8s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  dropout_rate=0.0, learning_rate=0.01, score=0.843, total=   1.5s\n",
            "[CV] dropout_rate=0.0, learning_rate=0.01 ............................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:   10.3s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  dropout_rate=0.0, learning_rate=0.01, score=0.922, total=   1.2s\n",
            "[CV] dropout_rate=0.0, learning_rate=0.01 ............................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:   11.5s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  dropout_rate=0.0, learning_rate=0.01, score=0.911, total=   1.3s\n",
            "[CV] dropout_rate=0.0, learning_rate=0.1 .............................\n",
            "[CV] . dropout_rate=0.0, learning_rate=0.1, score=0.863, total=   1.2s\n",
            "[CV] dropout_rate=0.0, learning_rate=0.1 .............................\n",
            "[CV] . dropout_rate=0.0, learning_rate=0.1, score=0.833, total=   1.2s\n",
            "[CV] dropout_rate=0.0, learning_rate=0.1 .............................\n",
            "[CV] . dropout_rate=0.0, learning_rate=0.1, score=0.814, total=   1.2s\n",
            "[CV] dropout_rate=0.0, learning_rate=0.1 .............................\n",
            "[CV] . dropout_rate=0.0, learning_rate=0.1, score=0.863, total=   1.2s\n",
            "[CV] dropout_rate=0.0, learning_rate=0.1 .............................\n",
            "[CV] . dropout_rate=0.0, learning_rate=0.1, score=0.871, total=   1.2s\n",
            "[CV] dropout_rate=0.1, learning_rate=0.001 ...........................\n",
            "[CV]  dropout_rate=0.1, learning_rate=0.001, score=0.971, total=   1.3s\n",
            "[CV] dropout_rate=0.1, learning_rate=0.001 ...........................\n",
            "[CV]  dropout_rate=0.1, learning_rate=0.001, score=0.765, total=   1.2s\n",
            "[CV] dropout_rate=0.1, learning_rate=0.001 ...........................\n",
            "[CV]  dropout_rate=0.1, learning_rate=0.001, score=0.647, total=   1.6s\n",
            "[CV] dropout_rate=0.1, learning_rate=0.001 ...........................\n",
            "[CV]  dropout_rate=0.1, learning_rate=0.001, score=0.745, total=   1.3s\n",
            "[CV] dropout_rate=0.1, learning_rate=0.001 ...........................\n",
            "[CV]  dropout_rate=0.1, learning_rate=0.001, score=0.802, total=   1.3s\n",
            "[CV] dropout_rate=0.1, learning_rate=0.01 ............................\n",
            "[CV]  dropout_rate=0.1, learning_rate=0.01, score=0.980, total=   1.3s\n",
            "[CV] dropout_rate=0.1, learning_rate=0.01 ............................\n",
            "[CV]  dropout_rate=0.1, learning_rate=0.01, score=0.892, total=   1.3s\n",
            "[CV] dropout_rate=0.1, learning_rate=0.01 ............................\n",
            "[CV]  dropout_rate=0.1, learning_rate=0.01, score=0.892, total=   1.2s\n",
            "[CV] dropout_rate=0.1, learning_rate=0.01 ............................\n",
            "[CV]  dropout_rate=0.1, learning_rate=0.01, score=0.892, total=   1.3s\n",
            "[CV] dropout_rate=0.1, learning_rate=0.01 ............................\n",
            "[CV]  dropout_rate=0.1, learning_rate=0.01, score=0.921, total=   1.3s\n",
            "[CV] dropout_rate=0.1, learning_rate=0.1 .............................\n",
            "[CV] . dropout_rate=0.1, learning_rate=0.1, score=0.951, total=   1.3s\n",
            "[CV] dropout_rate=0.1, learning_rate=0.1 .............................\n",
            "[CV] . dropout_rate=0.1, learning_rate=0.1, score=0.765, total=   1.6s\n",
            "[CV] dropout_rate=0.1, learning_rate=0.1 .............................\n",
            "[CV] . dropout_rate=0.1, learning_rate=0.1, score=0.775, total=   1.3s\n",
            "[CV] dropout_rate=0.1, learning_rate=0.1 .............................\n",
            "[CV] . dropout_rate=0.1, learning_rate=0.1, score=0.824, total=   1.3s\n",
            "[CV] dropout_rate=0.1, learning_rate=0.1 .............................\n",
            "[CV] . dropout_rate=0.1, learning_rate=0.1, score=0.881, total=   1.3s\n",
            "[CV] dropout_rate=0.2, learning_rate=0.001 ...........................\n",
            "[CV]  dropout_rate=0.2, learning_rate=0.001, score=0.990, total=   1.3s\n",
            "[CV] dropout_rate=0.2, learning_rate=0.001 ...........................\n",
            "[CV]  dropout_rate=0.2, learning_rate=0.001, score=0.765, total=   1.3s\n",
            "[CV] dropout_rate=0.2, learning_rate=0.001 ...........................\n",
            "[CV]  dropout_rate=0.2, learning_rate=0.001, score=0.647, total=   1.2s\n",
            "[CV] dropout_rate=0.2, learning_rate=0.001 ...........................\n",
            "[CV]  dropout_rate=0.2, learning_rate=0.001, score=0.765, total=   1.2s\n",
            "[CV] dropout_rate=0.2, learning_rate=0.001 ...........................\n",
            "[CV]  dropout_rate=0.2, learning_rate=0.001, score=0.733, total=   1.3s\n",
            "[CV] dropout_rate=0.2, learning_rate=0.01 ............................\n",
            "[CV]  dropout_rate=0.2, learning_rate=0.01, score=1.000, total=   1.6s\n",
            "[CV] dropout_rate=0.2, learning_rate=0.01 ............................\n",
            "[CV]  dropout_rate=0.2, learning_rate=0.01, score=0.882, total=   1.3s\n",
            "[CV] dropout_rate=0.2, learning_rate=0.01 ............................\n",
            "[CV]  dropout_rate=0.2, learning_rate=0.01, score=0.882, total=   1.3s\n",
            "[CV] dropout_rate=0.2, learning_rate=0.01 ............................\n",
            "[CV]  dropout_rate=0.2, learning_rate=0.01, score=0.912, total=   1.2s\n",
            "[CV] dropout_rate=0.2, learning_rate=0.01 ............................\n",
            "[CV]  dropout_rate=0.2, learning_rate=0.01, score=0.901, total=   1.3s\n",
            "[CV] dropout_rate=0.2, learning_rate=0.1 .............................\n",
            "[CV] . dropout_rate=0.2, learning_rate=0.1, score=1.000, total=   1.3s\n",
            "[CV] dropout_rate=0.2, learning_rate=0.1 .............................\n",
            "[CV] . dropout_rate=0.2, learning_rate=0.1, score=0.794, total=   1.3s\n",
            "[CV] dropout_rate=0.2, learning_rate=0.1 .............................\n",
            "[CV] . dropout_rate=0.2, learning_rate=0.1, score=0.775, total=   1.3s\n",
            "[CV] dropout_rate=0.2, learning_rate=0.1 .............................\n",
            "[CV] . dropout_rate=0.2, learning_rate=0.1, score=0.784, total=   1.3s\n",
            "[CV] dropout_rate=0.2, learning_rate=0.1 .............................\n",
            "[CV] . dropout_rate=0.2, learning_rate=0.1, score=0.693, total=   1.3s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed:   58.2s finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1c64993",
        "outputId": "12ab9f90-c510-4a9d-de22-cc4156b5d1e5"
      },
      "source": [
        "print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "  print('{},{} with: {}'.format(mean, stdev, param))"
      ],
      "id": "f1c64993",
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best : 0.9155309557914734, using {'dropout_rate': 0.1, 'learning_rate': 0.01}\n",
            "0.7838866353034973,0.0936300587843167 with: {'dropout_rate': 0.0, 'learning_rate': 0.001}\n",
            "0.9076684236526489,0.05460969971160176 with: {'dropout_rate': 0.0, 'learning_rate': 0.01}\n",
            "0.8487672209739685,0.0217441373571461 with: {'dropout_rate': 0.0, 'learning_rate': 0.1}\n",
            "0.7858862400054931,0.10560223570789992 with: {'dropout_rate': 0.1, 'learning_rate': 0.001}\n",
            "0.9155309557914734,0.03427448957857245 with: {'dropout_rate': 0.1, 'learning_rate': 0.01}\n",
            "0.8389827132225036,0.0696238122328201 with: {'dropout_rate': 0.1, 'learning_rate': 0.1}\n",
            "0.7798679947853089,0.11363386794755997 with: {'dropout_rate': 0.2, 'learning_rate': 0.001}\n",
            "0.9154921412467957,0.043731436643900015 with: {'dropout_rate': 0.2, 'learning_rate': 0.01}\n",
            "0.8092020869255065,0.10192271488780032 with: {'dropout_rate': 0.2, 'learning_rate': 0.1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0898455b"
      },
      "source": [
        "# Tuning of Hyperparameters:- Activation Function and Kernel Initializer"
      ],
      "id": "0898455b"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20fe4fb7",
        "outputId": "6cb65c8f-cc54-4fa2-bd77-c0b9bec6f51e"
      },
      "source": [
        "def create_model(activation_function,init):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(8,input_dim = 28,kernel_initializer = init,activation = activation_function))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(12,input_dim = 28,kernel_initializer = init,activation = activation_function))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(1,activation = 'sigmoid'))\n",
        "    \n",
        "    adam = Adam(lr = 0.001)\n",
        "    model.compile(loss = 'binary_crossentropy',optimizer = adam,metrics = ['accuracy'])\n",
        "    return model\n",
        "\n",
        "model = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 40,epochs = 50)\n",
        "\n",
        "activation_function = ['softmax','relu','tanh','linear']\n",
        "init = ['uniform','normal','zero']\n",
        "\n",
        "param_grids = dict(activation_function = activation_function,init = init)\n",
        "\n",
        "grid = GridSearchCV(estimator = model,param_grid = param_grids,cv = KFold(),verbose = 10)\n",
        "grid_result = grid.fit(X_standardized,Y)"
      ],
      "id": "20fe4fb7",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
            "[CV] activation_function=softmax, init=uniform .......................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation_function=softmax, init=uniform, score=1.000, total=   2.0s\n",
            "[CV] activation_function=softmax, init=uniform .......................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation_function=softmax, init=uniform, score=0.765, total=   2.0s\n",
            "[CV] activation_function=softmax, init=uniform .......................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation_function=softmax, init=uniform, score=0.510, total=   2.0s\n",
            "[CV] activation_function=softmax, init=uniform .......................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    5.9s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation_function=softmax, init=uniform, score=0.676, total=   1.3s\n",
            "[CV] activation_function=softmax, init=uniform .......................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    7.2s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation_function=softmax, init=uniform, score=0.693, total=   1.3s\n",
            "[CV] activation_function=softmax, init=normal ........................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    8.5s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation_function=softmax, init=normal, score=1.000, total=   1.3s\n",
            "[CV] activation_function=softmax, init=normal ........................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    9.8s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation_function=softmax, init=normal, score=0.765, total=   1.3s\n",
            "[CV] activation_function=softmax, init=normal ........................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:   11.1s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation_function=softmax, init=normal, score=0.510, total=   1.3s\n",
            "[CV] activation_function=softmax, init=normal ........................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:   12.5s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation_function=softmax, init=normal, score=0.676, total=   1.6s\n",
            "[CV] activation_function=softmax, init=normal ........................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:   14.1s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation_function=softmax, init=normal, score=0.693, total=   1.3s\n",
            "[CV] activation_function=softmax, init=zero ..........................\n",
            "[CV]  activation_function=softmax, init=zero, score=1.000, total=   1.3s\n",
            "[CV] activation_function=softmax, init=zero ..........................\n",
            "[CV]  activation_function=softmax, init=zero, score=0.765, total=   1.3s\n",
            "[CV] activation_function=softmax, init=zero ..........................\n",
            "[CV]  activation_function=softmax, init=zero, score=0.510, total=   1.3s\n",
            "[CV] activation_function=softmax, init=zero ..........................\n",
            "[CV]  activation_function=softmax, init=zero, score=0.676, total=   1.9s\n",
            "[CV] activation_function=softmax, init=zero ..........................\n",
            "[CV]  activation_function=softmax, init=zero, score=0.693, total=   1.9s\n",
            "[CV] activation_function=relu, init=uniform ..........................\n",
            "[CV]  activation_function=relu, init=uniform, score=1.000, total=   1.2s\n",
            "[CV] activation_function=relu, init=uniform ..........................\n",
            "[CV]  activation_function=relu, init=uniform, score=0.765, total=   1.6s\n",
            "[CV] activation_function=relu, init=uniform ..........................\n",
            "[CV]  activation_function=relu, init=uniform, score=0.696, total=   1.3s\n",
            "[CV] activation_function=relu, init=uniform ..........................\n",
            "[CV]  activation_function=relu, init=uniform, score=0.745, total=   1.3s\n",
            "[CV] activation_function=relu, init=uniform ..........................\n",
            "[CV]  activation_function=relu, init=uniform, score=0.762, total=   1.3s\n",
            "[CV] activation_function=relu, init=normal ...........................\n",
            "[CV]  activation_function=relu, init=normal, score=0.990, total=   1.2s\n",
            "[CV] activation_function=relu, init=normal ...........................\n",
            "[CV]  activation_function=relu, init=normal, score=0.765, total=   1.3s\n",
            "[CV] activation_function=relu, init=normal ...........................\n",
            "[CV]  activation_function=relu, init=normal, score=0.510, total=   1.9s\n",
            "[CV] activation_function=relu, init=normal ...........................\n",
            "[CV]  activation_function=relu, init=normal, score=0.765, total=   1.3s\n",
            "[CV] activation_function=relu, init=normal ...........................\n",
            "[CV]  activation_function=relu, init=normal, score=0.743, total=   1.3s\n",
            "[CV] activation_function=relu, init=zero .............................\n",
            "[CV] . activation_function=relu, init=zero, score=1.000, total=   1.2s\n",
            "[CV] activation_function=relu, init=zero .............................\n",
            "[CV] . activation_function=relu, init=zero, score=0.765, total=   1.6s\n",
            "[CV] activation_function=relu, init=zero .............................\n",
            "[CV] . activation_function=relu, init=zero, score=0.510, total=   1.3s\n",
            "[CV] activation_function=relu, init=zero .............................\n",
            "[CV] . activation_function=relu, init=zero, score=0.676, total=   1.3s\n",
            "[CV] activation_function=relu, init=zero .............................\n",
            "[CV] . activation_function=relu, init=zero, score=0.693, total=   1.2s\n",
            "[CV] activation_function=tanh, init=uniform ..........................\n",
            "[CV]  activation_function=tanh, init=uniform, score=0.990, total=   1.3s\n",
            "[CV] activation_function=tanh, init=uniform ..........................\n",
            "[CV]  activation_function=tanh, init=uniform, score=0.775, total=   1.3s\n",
            "[CV] activation_function=tanh, init=uniform ..........................\n",
            "[CV]  activation_function=tanh, init=uniform, score=0.833, total=   1.9s\n",
            "[CV] activation_function=tanh, init=uniform ..........................\n",
            "[CV]  activation_function=tanh, init=uniform, score=0.853, total=   1.3s\n",
            "[CV] activation_function=tanh, init=uniform ..........................\n",
            "[CV]  activation_function=tanh, init=uniform, score=0.871, total=   1.3s\n",
            "[CV] activation_function=tanh, init=normal ...........................\n",
            "[CV]  activation_function=tanh, init=normal, score=0.990, total=   1.3s\n",
            "[CV] activation_function=tanh, init=normal ...........................\n",
            "[CV]  activation_function=tanh, init=normal, score=0.765, total=   1.6s\n",
            "[CV] activation_function=tanh, init=normal ...........................\n",
            "[CV]  activation_function=tanh, init=normal, score=0.843, total=   1.9s\n",
            "[CV] activation_function=tanh, init=normal ...........................\n",
            "[CV]  activation_function=tanh, init=normal, score=0.833, total=   1.3s\n",
            "[CV] activation_function=tanh, init=normal ...........................\n",
            "[CV]  activation_function=tanh, init=normal, score=0.842, total=   1.3s\n",
            "[CV] activation_function=tanh, init=zero .............................\n",
            "[CV] . activation_function=tanh, init=zero, score=1.000, total=   1.3s\n",
            "[CV] activation_function=tanh, init=zero .............................\n",
            "[CV] . activation_function=tanh, init=zero, score=0.765, total=   1.3s\n",
            "[CV] activation_function=tanh, init=zero .............................\n",
            "[CV] . activation_function=tanh, init=zero, score=0.510, total=   1.3s\n",
            "[CV] activation_function=tanh, init=zero .............................\n",
            "[CV] . activation_function=tanh, init=zero, score=0.676, total=   1.2s\n",
            "[CV] activation_function=tanh, init=zero .............................\n",
            "[CV] . activation_function=tanh, init=zero, score=0.693, total=   1.5s\n",
            "[CV] activation_function=linear, init=uniform ........................\n",
            "[CV]  activation_function=linear, init=uniform, score=0.990, total=   1.4s\n",
            "[CV] activation_function=linear, init=uniform ........................\n",
            "[CV]  activation_function=linear, init=uniform, score=0.784, total=   1.3s\n",
            "[CV] activation_function=linear, init=uniform ........................\n",
            "[CV]  activation_function=linear, init=uniform, score=0.833, total=   1.3s\n",
            "[CV] activation_function=linear, init=uniform ........................\n",
            "[CV]  activation_function=linear, init=uniform, score=0.833, total=   1.3s\n",
            "[CV] activation_function=linear, init=uniform ........................\n",
            "[CV]  activation_function=linear, init=uniform, score=0.871, total=   1.3s\n",
            "[CV] activation_function=linear, init=normal .........................\n",
            "[CV]  activation_function=linear, init=normal, score=0.990, total=   1.2s\n",
            "[CV] activation_function=linear, init=normal .........................\n",
            "[CV]  activation_function=linear, init=normal, score=0.775, total=   1.3s\n",
            "[CV] activation_function=linear, init=normal .........................\n",
            "[CV]  activation_function=linear, init=normal, score=0.794, total=   1.2s\n",
            "[CV] activation_function=linear, init=normal .........................\n",
            "[CV]  activation_function=linear, init=normal, score=0.824, total=   1.6s\n",
            "[CV] activation_function=linear, init=normal .........................\n",
            "[CV]  activation_function=linear, init=normal, score=0.861, total=   1.3s\n",
            "[CV] activation_function=linear, init=zero ...........................\n",
            "[CV]  activation_function=linear, init=zero, score=1.000, total=   1.3s\n",
            "[CV] activation_function=linear, init=zero ...........................\n",
            "[CV]  activation_function=linear, init=zero, score=0.765, total=   1.2s\n",
            "[CV] activation_function=linear, init=zero ...........................\n",
            "[CV]  activation_function=linear, init=zero, score=0.510, total=   1.3s\n",
            "[CV] activation_function=linear, init=zero ...........................\n",
            "[CV]  activation_function=linear, init=zero, score=0.676, total=   1.3s\n",
            "[CV] activation_function=linear, init=zero ...........................\n",
            "[CV]  activation_function=linear, init=zero, score=0.693, total=   1.2s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed:  1.4min finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24610c53",
        "outputId": "08312c4e-80d4-440e-8c6f-81593a3045e2"
      },
      "source": [
        "print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "  print('{},{} with: {}'.format(mean, stdev, param))"
      ],
      "id": "24610c53",
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best : 0.8644534826278687, using {'activation_function': 'tanh', 'init': 'uniform'}\n",
            "0.728809940814972,0.1592563941055272 with: {'activation_function': 'softmax', 'init': 'uniform'}\n",
            "0.728809940814972,0.1592563941055272 with: {'activation_function': 'softmax', 'init': 'normal'}\n",
            "0.728809940814972,0.1592563941055272 with: {'activation_function': 'softmax', 'init': 'zero'}\n",
            "0.7936517238616944,0.10608829891863436 with: {'activation_function': 'relu', 'init': 'uniform'}\n",
            "0.7543972134590149,0.15217047996216865 with: {'activation_function': 'relu', 'init': 'normal'}\n",
            "0.728809940814972,0.1592563941055272 with: {'activation_function': 'relu', 'init': 'zero'}\n",
            "0.8644534826278687,0.07077959927643684 with: {'activation_function': 'tanh', 'init': 'uniform'}\n",
            "0.8545913338661194,0.07378389631162245 with: {'activation_function': 'tanh', 'init': 'normal'}\n",
            "0.728809940814972,0.1592563941055272 with: {'activation_function': 'tanh', 'init': 'zero'}\n",
            "0.8624927043914795,0.06956720016572787 with: {'activation_function': 'linear', 'init': 'uniform'}\n",
            "0.8487478017807006,0.0765493813660326 with: {'activation_function': 'linear', 'init': 'normal'}\n",
            "0.728809940814972,0.1592563941055272 with: {'activation_function': 'linear', 'init': 'zero'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bd398775"
      },
      "source": [
        "# Tuning of Hyperparameter :-Number of Neurons in activation layer"
      ],
      "id": "bd398775"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81f23631",
        "outputId": "5cbb48cd-63f0-4050-9afd-44eac88bd2ed"
      },
      "source": [
        "def create_model(neuron1,neuron2):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(neuron1,input_dim = 28,kernel_initializer = 'uniform',activation = 'linear'))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(neuron2,input_dim = neuron1,kernel_initializer = 'uniform',activation = 'linear'))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(1,activation = 'sigmoid'))\n",
        "    \n",
        "    adam = Adam(lr = 0.001)\n",
        "    model.compile(loss = 'binary_crossentropy',optimizer = adam,metrics = ['accuracy'])\n",
        "    return model\n",
        "\n",
        "model = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 40,epochs = 50)\n",
        "\n",
        "neuron1 = [4,8,16]\n",
        "neuron2 = [2,4,8]\n",
        "\n",
        "param_grids = dict(neuron1 = neuron1,neuron2 = neuron2)\n",
        "\n",
        "grid = GridSearchCV(estimator = model,param_grid = param_grids,cv = KFold(),verbose = 10)\n",
        "grid_result = grid.fit(X_standardized,Y)\n"
      ],
      "id": "81f23631",
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
            "[CV] neuron1=4, neuron2=2 ............................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ................ neuron1=4, neuron2=2, score=0.971, total=   1.3s\n",
            "[CV] neuron1=4, neuron2=2 ............................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.3s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ................ neuron1=4, neuron2=2, score=0.765, total=   2.3s\n",
            "[CV] neuron1=4, neuron2=2 ............................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.6s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ................ neuron1=4, neuron2=2, score=0.696, total=   1.3s\n",
            "[CV] neuron1=4, neuron2=2 ............................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    4.9s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ................ neuron1=4, neuron2=2, score=0.716, total=   1.3s\n",
            "[CV] neuron1=4, neuron2=2 ............................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    6.2s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ................ neuron1=4, neuron2=2, score=0.733, total=   1.2s\n",
            "[CV] neuron1=4, neuron2=4 ............................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    7.4s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ................ neuron1=4, neuron2=4, score=0.990, total=   1.3s\n",
            "[CV] neuron1=4, neuron2=4 ............................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    8.7s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ................ neuron1=4, neuron2=4, score=0.765, total=   1.3s\n",
            "[CV] neuron1=4, neuron2=4 ............................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:   10.0s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ................ neuron1=4, neuron2=4, score=0.716, total=   1.3s\n",
            "[CV] neuron1=4, neuron2=4 ............................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:   11.3s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ................ neuron1=4, neuron2=4, score=0.716, total=   1.3s\n",
            "[CV] neuron1=4, neuron2=4 ............................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:   12.6s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ................ neuron1=4, neuron2=4, score=0.752, total=   1.3s\n",
            "[CV] neuron1=4, neuron2=8 ............................................\n",
            "[CV] ................ neuron1=4, neuron2=8, score=0.971, total=   1.3s\n",
            "[CV] neuron1=4, neuron2=8 ............................................\n",
            "[CV] ................ neuron1=4, neuron2=8, score=0.765, total=   1.6s\n",
            "[CV] neuron1=4, neuron2=8 ............................................\n",
            "[CV] ................ neuron1=4, neuron2=8, score=0.716, total=   1.3s\n",
            "[CV] neuron1=4, neuron2=8 ............................................\n",
            "[CV] ................ neuron1=4, neuron2=8, score=0.765, total=   1.3s\n",
            "[CV] neuron1=4, neuron2=8 ............................................\n",
            "[CV] ................ neuron1=4, neuron2=8, score=0.772, total=   1.3s\n",
            "[CV] neuron1=8, neuron2=2 ............................................\n",
            "[CV] ................ neuron1=8, neuron2=2, score=0.990, total=   1.3s\n",
            "[CV] neuron1=8, neuron2=2 ............................................\n",
            "[CV] ................ neuron1=8, neuron2=2, score=0.765, total=   1.3s\n",
            "[CV] neuron1=8, neuron2=2 ............................................\n",
            "[CV] ................ neuron1=8, neuron2=2, score=0.725, total=   1.3s\n",
            "[CV] neuron1=8, neuron2=2 ............................................\n",
            "[CV] ................ neuron1=8, neuron2=2, score=0.755, total=   1.2s\n",
            "[CV] neuron1=8, neuron2=2 ............................................\n",
            "[CV] ................ neuron1=8, neuron2=2, score=0.762, total=   1.2s\n",
            "[CV] neuron1=8, neuron2=4 ............................................\n",
            "[CV] ................ neuron1=8, neuron2=4, score=0.990, total=   1.3s\n",
            "[CV] neuron1=8, neuron2=4 ............................................\n",
            "[CV] ................ neuron1=8, neuron2=4, score=0.765, total=   1.6s\n",
            "[CV] neuron1=8, neuron2=4 ............................................\n",
            "[CV] ................ neuron1=8, neuron2=4, score=0.784, total=   1.3s\n",
            "[CV] neuron1=8, neuron2=4 ............................................\n",
            "[CV] ................ neuron1=8, neuron2=4, score=0.804, total=   1.2s\n",
            "[CV] neuron1=8, neuron2=4 ............................................\n",
            "[CV] ................ neuron1=8, neuron2=4, score=0.832, total=   1.3s\n",
            "[CV] neuron1=8, neuron2=8 ............................................\n",
            "[CV] ................ neuron1=8, neuron2=8, score=0.990, total=   1.3s\n",
            "[CV] neuron1=8, neuron2=8 ............................................\n",
            "[CV] ................ neuron1=8, neuron2=8, score=0.775, total=   1.3s\n",
            "[CV] neuron1=8, neuron2=8 ............................................\n",
            "[CV] ................ neuron1=8, neuron2=8, score=0.804, total=   1.3s\n",
            "[CV] neuron1=8, neuron2=8 ............................................\n",
            "[CV] ................ neuron1=8, neuron2=8, score=0.794, total=   1.3s\n",
            "[CV] neuron1=8, neuron2=8 ............................................\n",
            "[CV] ................ neuron1=8, neuron2=8, score=0.871, total=   1.6s\n",
            "[CV] neuron1=16, neuron2=2 ...........................................\n",
            "[CV] ............... neuron1=16, neuron2=2, score=0.990, total=   1.9s\n",
            "[CV] neuron1=16, neuron2=2 ...........................................\n",
            "[CV] ............... neuron1=16, neuron2=2, score=0.765, total=   1.9s\n",
            "[CV] neuron1=16, neuron2=2 ...........................................\n",
            "[CV] ............... neuron1=16, neuron2=2, score=0.784, total=   1.4s\n",
            "[CV] neuron1=16, neuron2=2 ...........................................\n",
            "[CV] ............... neuron1=16, neuron2=2, score=0.755, total=   1.3s\n",
            "[CV] neuron1=16, neuron2=2 ...........................................\n",
            "[CV] ............... neuron1=16, neuron2=2, score=0.842, total=   1.9s\n",
            "[CV] neuron1=16, neuron2=4 ...........................................\n",
            "[CV] ............... neuron1=16, neuron2=4, score=0.990, total=   1.9s\n",
            "[CV] neuron1=16, neuron2=4 ...........................................\n",
            "[CV] ............... neuron1=16, neuron2=4, score=0.775, total=   1.9s\n",
            "[CV] neuron1=16, neuron2=4 ...........................................\n",
            "[CV] ............... neuron1=16, neuron2=4, score=0.794, total=   1.9s\n",
            "[CV] neuron1=16, neuron2=4 ...........................................\n",
            "[CV] ............... neuron1=16, neuron2=4, score=0.814, total=   1.9s\n",
            "[CV] neuron1=16, neuron2=4 ...........................................\n",
            "[CV] ............... neuron1=16, neuron2=4, score=0.842, total=   1.7s\n",
            "[CV] neuron1=16, neuron2=8 ...........................................\n",
            "[CV] ............... neuron1=16, neuron2=8, score=0.990, total=   1.9s\n",
            "[CV] neuron1=16, neuron2=8 ...........................................\n",
            "[CV] ............... neuron1=16, neuron2=8, score=0.804, total=   2.0s\n",
            "[CV] neuron1=16, neuron2=8 ...........................................\n",
            "[CV] ............... neuron1=16, neuron2=8, score=0.824, total=   1.3s\n",
            "[CV] neuron1=16, neuron2=8 ...........................................\n",
            "[CV] ............... neuron1=16, neuron2=8, score=0.843, total=   1.9s\n",
            "[CV] neuron1=16, neuron2=8 ...........................................\n",
            "[CV] ............... neuron1=16, neuron2=8, score=0.881, total=   1.4s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed:  1.1min finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dc9b39f7",
        "outputId": "9b8e860a-54b1-492c-86f7-e91636b780c5"
      },
      "source": [
        "print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "  print('{},{} with: {}'.format(mean, stdev, param))"
      ],
      "id": "dc9b39f7",
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best : 0.8683944821357727, using {'neuron1': 16, 'neuron2': 8}\n",
            "0.7759464144706726,0.09989446719121069 with: {'neuron1': 4, 'neuron2': 2}\n",
            "0.7877499461174011,0.10309811393586134 with: {'neuron1': 4, 'neuron2': 4}\n",
            "0.7975926995277405,0.08881448822434385 with: {'neuron1': 4, 'neuron2': 8}\n",
            "0.7995340704917908,0.09635373894211088 with: {'neuron1': 8, 'neuron2': 2}\n",
            "0.8349640846252442,0.0807131153798453 with: {'neuron1': 8, 'neuron2': 4}\n",
            "0.8468064308166504,0.07874250567935916 with: {'neuron1': 8, 'neuron2': 8}\n",
            "0.8271403551101685,0.0868865363862206 with: {'neuron1': 16, 'neuron2': 2}\n",
            "0.8428266167640686,0.07694923599359135 with: {'neuron1': 16, 'neuron2': 4}\n",
            "0.8683944821357727,0.06604067531895626 with: {'neuron1': 16, 'neuron2': 8}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ac4ba095",
        "outputId": "701b8e93-27f9-4d8f-e8b6-e6597ba50b69"
      },
      "source": [
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "def create_model():\n",
        "    model = Sequential()\n",
        "    model.add(Dense(16,input_dim = 28,kernel_initializer = 'uniform',activation = 'tanh'))\n",
        "    model.add(Dropout(0.1))\n",
        "    model.add(Dense(4,input_dim = 56,kernel_initializer = 'uniform',activation = 'tanh'))\n",
        "    model.add(Dropout(0.1))\n",
        "    model.add(Dense(1,activation = 'sigmoid'))\n",
        "    \n",
        "    adam = Adam(lr = 0.001) #sgd = SGD(lr=learning_rate, momentum=momentum, decay=decay_rate, nesterov=False)\n",
        "    model.compile(loss = 'binary_crossentropy',optimizer = adam,metrics = ['accuracy'])\n",
        "    return model\n",
        "\n",
        "model = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 40,epochs = 10)\n",
        "\n",
        "model.fit(X_standardized,Y)\n",
        "\n",
        "y_predict = model.predict(X_standardized)\n",
        "\n",
        "print(accuracy_score(Y,y_predict))"
      ],
      "id": "ac4ba095",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.7760314341846758\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdd65cdd"
      },
      "source": [
        "so from the accuracy we can tell that about 77% of the area is burnt"
      ],
      "id": "cdd65cdd"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ylu9PW2PPV9l"
      },
      "source": [
        ""
      ],
      "id": "Ylu9PW2PPV9l",
      "execution_count": null,
      "outputs": []
    }
  ]
}